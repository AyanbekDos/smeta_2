import os
import logging
import io
import json
import base64
import tempfile
import fitz  # PyMuPDF
import pandas as pd
import google.generativeai as genai
import asyncio
import httpx
from dotenv import load_dotenv
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ConversationHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)
from azure.core.credentials import AzureKeyCredential
from azure.ai.documentintelligence.aio import DocumentIntelligenceClient
from azure.ai.documentintelligence.models import AnalyzeResult, DocumentTable
from google.generativeai.types import GenerationConfig

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
load_dotenv()

# API –ö–ª—é—á–∏
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL_NAME = os.getenv("GEMINI_MODEL_NAME", "gemini-1.5-pro-latest") # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ
AZURE_ENDPOINT = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT")
AZURE_KEY = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

genai.configure(api_key=GEMINI_API_KEY)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - [%(levelname)s] - (%(name)s) - %(message)s",
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
(SELECTING_ACTION, AWAITING_CONFIRMATION, AWAITING_MANUAL_PAGE) = range(3)
TEMP_DIR = "temp_bot_files"
MAX_RETRIES = 3

# --- –§—É–Ω–∫—Ü–∏–∏-–ø–æ–º–æ—â–Ω–∏–∫–∏ ---

def get_prompt(file_path: str) -> str:
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        logger.error(f"Prompt file not found: {file_path}")
        return ""

def create_ocr_correction_prompt(ocr_text: str) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ OCR –æ—à–∏–±–æ–∫, –∏—Å–ø–æ–ª—å–∑—É—è –ª–æ–≥–∏–∫—É –∏–∑ 2b_ocr_correction.py.
    """
    prompt = f"""
üîß –ó–ê–î–ê–ß–ê: –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –æ—à–∏–±–æ–∫ OCR –≤ —Ç–∞–±–ª–∏—Ü–µ –º–µ—Ç–∞–ª–ª–æ–ø—Ä–æ–∫–∞—Ç–∞

üìã –ò–°–•–û–î–ù–´–ô –¢–ï–ö–°–¢ OCR:
{ocr_text}

üéØ –¶–ï–õ–¨: –ò—Å–ø—Ä–∞–≤–∏—Ç—å —Ç–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ OCR —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã

‚ö° –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:

1. **–†–ê–ó–ú–ï–†–´ –ü–†–û–§–ò–õ–ï–ô:**
   - 20–ë1, 20–ëI, 20BI ‚Üí 20–®1 (–¥–≤—É—Ç–∞–≤—Ä —à–∏—Ä–æ–∫–æ–ø–æ–ª–æ—á–Ω—ã–π)
   - [16n, [16–ø ‚Üí 16–ø (—à–≤–µ–ª–ª–µ—Ä)  
   - [200, [120 ‚Üí 200, 120 (—à–≤–µ–ª–ª–µ—Ä)
   - C247 ‚Üí 24–£ (—à–≤–µ–ª–ª–µ—Ä —Å —É–∫–ª–æ–Ω–æ–º)
   - +5, s5 ‚Üí s5 (–ª–∏—Å—Ç —Ç–æ–ª—â–∏–Ω–æ–π 5–º–º)
   - nucm ‚Üí –ª–∏—Å—Ç (–ø—Ä–æ—Å–µ—á–Ω–æ-–≤—ã—Ç—è–∂–Ω–æ–π)
   
2. **–ú–ê–†–ö–ò –°–¢–ê–õ–ò:**
   - –°5, –°—Ç5 ‚Üí –°—Ç3 (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ OCR –æ—à–∏–±–∫–∏)
   - –°6 ‚Üí –°235 (–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç)
   - C255, C245, C275 ‚Üí –°255, –°245, –°275 (–ª–∞—Ç–∏–Ω—Å–∫–∞—è C ‚Üí –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∞—è –°)
   
3. **–ù–ê–ó–í–ê–ù–ò–Ø –ü–†–û–§–ò–õ–ï–ô:**
   - –î–≤—É—Ç–∞–≤—Ä—ã ‚Üí –î–≤—É—Ç–∞–≤—Ä—ã —Å—Ç–∞–ª—å–Ω—ã–µ –≥–æ—Ä—è—á–µ–∫–∞—Ç–∞–Ω–Ω—ã–µ
   - –®–≤–µ–ª–ª–µ—Ä—ã ‚Üí –®–≤–µ–ª–ª–µ—Ä—ã —Å—Ç–∞–ª—å–Ω—ã–µ –≥–æ—Ä—è—á–µ–∫–∞—Ç–∞–Ω–Ω—ã–µ
   - –£–≥–æ–ª–∫–∏ ‚Üí –£–≥–æ–ª–∫–∏ —Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∞–≤–Ω–æ–ø–æ–ª–æ—á–Ω—ã–µ
   - –õ–∏—Å—Ç—ã ‚Üí –õ–∏—Å—Ç—ã —Å—Ç–∞–ª—å–Ω—ã–µ –≥–æ—Ä—è—á–µ–∫–∞—Ç–∞–Ω–Ω—ã–µ

4. **–ú–ê–°–°–´ –ò –ö–û–õ–ò–ß–ï–°–¢–í–ê:**
   - –ò—Å–ø—Ä–∞–≤—å –æ—á–µ–≤–∏–¥–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ —á–∏—Å–ª–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1O ‚Üí 10)
   - –°–æ—Ö—Ä–∞–Ω–∏ –¥–µ—Å—è—Ç–∏—á–Ω—ã–µ –¥—Ä–æ–±–∏ –∫–∞–∫ –µ—Å—Ç—å
   
üö® –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
- –û—à–∏–±–∫–∏ OCR —á–∞—â–µ –≤ –ë–£–ö–í–ê–•, —Ü–∏—Ñ—Ä—ã –≤ 99% —Å–ª—É—á–∞–µ–≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ
- –°–æ—Ö—Ä–∞–Ω–∏ –í–°–Æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã (—Å—Ç—Ä–æ–∫–∏, —Å—Ç–æ–ª–±—Ü—ã, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
- –ù–ï –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —Ç–æ–ª—å–∫–æ –∏—Å–ø—Ä–∞–≤–ª—è–π –æ—à–∏–±–∫–∏
- –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü –∫–∞–∫ –µ—Å—Ç—å
- –ò—Å–ø—Ä–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ –û–ß–ï–í–ò–î–ù–´–ï –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

üìã –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã –¥–æ–ª–∂–Ω–∞ –æ—Å—Ç–∞—Ç—å—Å—è –∏–¥–µ–Ω—Ç–∏—á–Ω–æ–π –∏—Å—Ö–æ–¥–Ω–æ–π.

üîç –ù–ê–ß–ò–ù–ê–ô –ö–û–†–†–ï–ö–¶–ò–Æ:
"""
    return prompt

def table_to_html(table: DocumentTable) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ–±—ä–µ–∫—Ç —Ç–∞–±–ª–∏—Ü—ã –∏–∑ Azure –≤ HTML-—Å—Ç—Ä–æ–∫—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–æ—Å—Ç—É—é —Å–µ—Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É."""
    if not table.cells:
        return ""
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ—Ç–∫—É —Ç–∞–±–ª–∏—Ü—ã
    grid = [['' for _ in range(table.column_count)] for _ in range(table.row_count)]
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º —Å–µ—Ç–∫—É —Å–æ–¥–µ—Ä–∂–∏–º—ã–º —è—á–µ–µ–∫
    for cell in table.cells:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–Ω–¥–µ–∫—Å—ã –Ω–µ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ –ø—Ä–µ–¥–µ–ª—ã —Å–µ—Ç–∫–∏
        if cell.row_index < table.row_count and cell.column_index < table.column_count:
            grid[cell.row_index][cell.column_index] = cell.content or ''

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML
    html_parts = ['<table border="1">']
    for row in grid:
        html_parts.append('<tr>')
        for cell_content in row:
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º HTML-—Å—É—â–Ω–æ—Å—Ç–∏
            import html
            html_parts.append(f'<td>{html.escape(cell_content)}</td>')
        html_parts.append('</tr>')
    html_parts.append('</table>')
    
    return '\n'.join(html_parts)

def flatten_json_to_dataframe(data: dict) -> pd.DataFrame:
    flat_list = []
    unit = data.get("–µ–¥–∏–Ω–∏—Ü–∞_–∏–∑–º–µ—Ä–µ–Ω–∏—è", "–Ω–µ —É–∫–∞–∑–∞–Ω–∞")
    for profile, p_data in data.get("–ø—Ä–æ—Ñ–∏–ª–∏", {}).items():
        for steel, s_data in p_data.get("–º–∞—Ä–∫–∏_—Å—Ç–∞–ª–∏", {}).items():
            for size, z_data in s_data.get("—Ä–∞–∑–º–µ—Ä—ã", {}).items():
                # –ò–∑–º–µ–Ω–µ–Ω–æ: —Ç–µ–ø–µ—Ä—å –ø–µ—Ä–µ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫, –∞ –Ω–µ —Å–ª–æ–≤–∞—Ä—å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
                for e_data in z_data.get("—ç–ª–µ–º–µ–Ω—Ç—ã", []):
                    flat_list.append({
                        "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è": profile,
                        "–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏": steel,
                        "–†–∞–∑–º–µ—Ä –ø—Ä–æ—Ñ–∏–ª—è": size,
                        "–¢–∏–ø —ç–ª–µ–º–µ–Ω—Ç–∞": e_data.get("—Ç–∏–ø"), # –î–∞–Ω–Ω—ã–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è –≤ —Å–ø–∏—Å–∫–µ
                        "–ü–æ–∑–∏—Ü–∏–∏": ", ".join(map(str, e_data.get("–ø–æ–∑–∏—Ü–∏–∏", []))),
                        f"–ú–∞—Å—Å–∞, {unit}": e_data.get("–º–∞—Å—Å–∞"),
                    })
    return pd.DataFrame(flat_list)

async def run_gemini_with_retry(model, prompt, gemini_file, user_id):
    retries = 0
    last_exception = None
    while retries < MAX_RETRIES:
        try:
            logger.info(f"[USER_ID: {user_id}] - Gemini API call attempt {retries + 1}")
            response = await model.generate_content_async([prompt, gemini_file])
            return response
        except Exception as e:
            last_exception = e
            if "500" in str(e) or "internal error" in str(e).lower():
                retries += 1
                wait_time = 5 * (2 ** (retries - 1))
                logger.warning(f"[USER_ID: {user_id}] - Server error. Retrying in {wait_time}s...")
                await asyncio.sleep(wait_time)
            else:
                raise e
    raise last_exception

# --- –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ --- 

async def process_specification(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat = update.effective_chat
    user_id = update.effective_user.id
    try:
        pdf_bytes = context.user_data["pdf_bytes"]
        page_number = context.user_data.get("manual_page_number") or context.user_data.get("found_page_number")

        # –≠—Ç–∞–ø 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ PNG –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å Azure
        logger.info(f"[USER_ID: {user_id}] - STEP 2: Extracting page {page_number} to PNG and sending to Azure...")
        pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
        page_to_ocr = pdf_document.load_page(page_number - 1)
        pix = page_to_ocr.get_pixmap(dpi=300)
        png_bytes = pix.tobytes("png")
        pdf_document.close()

        async with DocumentIntelligenceClient(endpoint=AZURE_ENDPOINT, credential=AzureKeyCredential(AZURE_KEY)) as client:
            poller = await client.begin_analyze_document("prebuilt-layout", png_bytes, content_type="application/octet-stream")
            result = await poller.result()
        if not result.tables:
            await chat.send_message("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–∞–±–ª–∏—Ü—É –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ.")
            return

        # --- –û–±—ä–µ–¥–∏–Ω—è–µ–º –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –≤ –æ–¥–∏–Ω HTML –¥–ª—è Gemini ---
        all_tables_html_parts = [table_to_html(table) for table in result.tables]
        full_html_content = "\n<hr>\n".join(all_tables_html_parts) # –°–æ–µ–¥–∏–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—ã –ª–∏–Ω–∏–µ–π
        logger.info(f"[USER_ID: {user_id}] - Combined HTML from {len(result.tables)} tables generated for Gemini.")

        # --- –û–¢–õ–ê–î–ö–ê: –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç—Ç–æ—Ç –∂–µ HTML –≤ —Ñ–∞–π–ª ---
        debug_file_path = os.path.join(TEMP_DIR, f"azure_output_{user_id}.html")
        with open(debug_file_path, "w", encoding="utf-8") as f:
            f.write(full_html_content)
        logger.info(f"[USER_ID: {user_id}] - Azure OCR debug HTML saved to {debug_file_path}")
        # --- –ö–û–ù–ï–¶ –û–¢–õ–ê–î–ö–ò ---

        # –≠—Ç–∞–ø 3: –ï–¥–∏–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON
        logger.info(f"[USER_ID: {user_id}] - STEP 3: Correcting and extracting JSON with Gemini...")
        prompt = get_prompt("extract_and_correct.txt")
        model = genai.GenerativeModel(model_name=GEMINI_MODEL_NAME)
        response = await model.generate_content_async([prompt, full_html_content], generation_config=GenerationConfig(response_mime_type="application/json"))
        
        json_data = json.loads(response.text)
        logger.info(f"[USER_ID: {user_id}] - JSON extracted successfully.")

        # --- –û–¢–õ–ê–î–ö–ê: –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é ---
        json_file_path = os.path.join(TEMP_DIR, f"structured_output_{user_id}.json")
        with open(json_file_path, "w", encoding="utf-8") as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        logger.info(f"[USER_ID: {user_id}] - JSON structured data saved to {json_file_path}")
        # --- –ö–û–ù–ï–¶ –û–¢–õ–ê–î–ö–ò JSON ---

        # –≠—Ç–∞–ø 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
        df = flatten_json_to_dataframe(json_data)
        txt_buffer = io.BytesIO(df.to_string(index=False).encode('utf-8'))
        xlsx_buffer = io.BytesIO()
        df.to_excel(xlsx_buffer, index=False, engine='openpyxl')
        xlsx_buffer.seek(0)

        await chat.send_message("–í–∞—à–∞ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞:")
        await chat.send_document(document=InputFile(xlsx_buffer, filename="specification.xlsx"))
        await chat.send_document(document=InputFile(txt_buffer, filename="specification.txt"))
        logger.info(f"[USER_ID: {user_id}] - FINAL: Reports sent.")

    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error in process_specification: {e}", exc_info=True)
        await chat.send_message("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ.")
    finally:
        context.user_data.clear()

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ó–∞–≥—Ä—É–∑–∏—Ç–µ PDF-—Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
    return SELECTING_ACTION

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    
    if not update.message.document:
        return

    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ –ü–ï–†–ï–î —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ–º ---
    if update.message.document.file_size > 20 * 1024 * 1024: # 20 MB limit
        logger.warning(f"[USER_ID: {user_id}] - PDF rejected: file too large ({update.message.document.file_size / 1024 / 1024:.2f} MB).")
        await update.message.reply_text(
            "–û—à–∏–±–∫–∞: –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Ä–∞–∑–º–µ—Ä–æ–º –Ω–µ –±–æ–ª–µ–µ 20 –ú–ë."
        )
        return ConversationHandler.END

    file_id = update.message.document.file_id
    file_name = update.message.document.file_name
    
    await update.message.reply_text(f"–§–∞–π–ª '{file_name}' –ø—Ä–∏–Ω—è—Ç. –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É...")

    try:
        file_info = await context.bot.get_file(file_id)
        
        file_url = file_info.file_path

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º httpx –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –ø–æ—Ç–æ–∫–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        async with httpx.AsyncClient() as client:
            async with client.stream("GET", file_url) as response:
                response.raise_for_status() # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫–∏ HTTP
                
                pdf_bytes_io = io.BytesIO()
                async for chunk in response.aiter_bytes():
                    pdf_bytes_io.write(chunk)
                pdf_bytes_io.seek(0)
                pdf_bytes = pdf_bytes_io.read()

        context.user_data["pdf_bytes"] = pdf_bytes
        logger.info(f"[USER_ID: {user_id}] - File '{file_name}' downloaded successfully.")

    except telegram.error.BadRequest as e:
        logger.error(f"[USER_ID: {user_id}] - Error getting file info: {e}", exc_info=True)
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ: {e}")
        return ConversationHandler.END
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error downloading file: {e}", exc_info=True)
        await update.message.reply_text(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞.")
        return ConversationHandler.END

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
    try:
        pdf_document_for_check = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
        num_pages = len(pdf_document_for_check)
        pdf_document_for_check.close()
        if num_pages > 100:
            logger.warning(f"[USER_ID: {user_id}] - PDF rejected: too many pages ({num_pages}).")
            await update.message.reply_text(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({num_pages} —Å—Ç—Ä–∞–Ω–∏—Ü). –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –Ω–µ –±–æ–ª–µ–µ 100 —Å—Ç—Ä–∞–Ω–∏—Ü.")
            return ConversationHandler.END
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Failed to check PDF page count: {e}")
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ PDF. –§–∞–π–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω.")
        return ConversationHandler.END

    await update.message.reply_text("–§–∞–π–ª –ø—Ä–∏–Ω—è—Ç. –ü—Ä–æ–≤–æ–∂—É –ø–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑...")

    temp_pdf_path = None
    try:
        os.makedirs(TEMP_DIR, exist_ok=True)
        temp_pdf_path = os.path.join(TEMP_DIR, f"{user_id}_check.pdf")
        with open(temp_pdf_path, "wb") as f:
            f.write(pdf_bytes)

        logger.info(f"[USER_ID: {user_id}] - STEP 1: Performing validation and page search with Gemini.")
        gemini_file = genai.upload_file(path=temp_pdf_path)
        prompt = get_prompt("find_and_validate.txt")
        model = genai.GenerativeModel(model_name=GEMINI_MODEL_NAME)
        
        response = await run_gemini_with_retry(model, prompt, gemini_file, user_id)
        genai.delete_file(gemini_file.name)

        try:
            cleaned_text = response.text.replace("```json", "").replace("```", "").strip()
            result = json.loads(cleaned_text)
        except (json.JSONDecodeError, AttributeError, ValueError) as e:
            logger.error(f"[USER_ID: {user_id}] - Failed to decode Gemini response: {e}", exc_info=True)
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–∏—Å–∞ –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")
            return ConversationHandler.END

        page_number = result.get("page", 0)
        if page_number == 0:
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—É. –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –≤—Ä—É—á–Ω—É—é.")
            return AWAITING_MANUAL_PAGE

        context.user_data["found_page_number"] = page_number
        pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
        page = pdf_document.load_page(page_number - 1)
        img_buffer = io.BytesIO(page.get_pixmap(dpi=200).tobytes("png"))

        keyboard = [[InlineKeyboardButton("‚úÖ –î–∞", callback_data="yes"), InlineKeyboardButton("‚ùå –ù–µ—Ç", callback_data="no")]]
        await update.message.reply_photo(
            photo=img_buffer,
            caption=f"–≠—Ç–æ –≤–µ—Ä–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number})?",
            reply_markup=InlineKeyboardMarkup(keyboard),
        )
        return AWAITING_CONFIRMATION

    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error in handle_document: {e}", exc_info=True)
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.")
        return ConversationHandler.END
    finally:
        if temp_pdf_path and os.path.exists(temp_pdf_path):
            os.remove(temp_pdf_path)

async def handle_confirmation_choice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    if query.data == "yes":
        await query.edit_message_caption(caption="–û—Ç–ª–∏—á–Ω–æ! –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
        await process_specification(update, context)
        return ConversationHandler.END
    else:
        await query.edit_message_caption(caption="–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã:")
        return AWAITING_MANUAL_PAGE

async def handle_manual_page_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        page_number = int(update.message.text)
        context.user_data["manual_page_number"] = page_number
        await update.message.reply_text(f"–ü—Ä–∏–Ω—è—Ç–æ. –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}...")
        await process_specification(update, context)
        return ConversationHandler.END
    except (ValueError):
        await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã.")
        return AWAITING_MANUAL_PAGE

async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–î–µ–π—Å—Ç–≤–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")
    context.user_data.clear()
    return ConversationHandler.END

def main():
    if not all([TELEGRAM_BOT_TOKEN, AZURE_ENDPOINT, AZURE_KEY, GEMINI_API_KEY]):
        logger.critical("FATAL: One or more environment variables are missing!")
        return

    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("start", start)],
        states={
            SELECTING_ACTION: [MessageHandler(filters.Document.PDF, handle_document)],
            AWAITING_CONFIRMATION: [CallbackQueryHandler(handle_confirmation_choice)],
            AWAITING_MANUAL_PAGE: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_manual_page_input)],
        },
        fallbacks=[CommandHandler("cancel", cancel)],
    )
    app.add_handler(conv_handler)
    logger.info("--- BOT INITIALIZED. STARTING POLLING... ---")
    app.run_polling()

if __name__ == "__main__":
    main()