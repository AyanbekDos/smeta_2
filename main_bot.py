import os
import logging
import io
import json
import base64
import tempfile
import re
import gzip
import uuid
from datetime import datetime, timezone
from PIL import Image
import fitz  # PyMuPDF
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
import google.generativeai as genai
import asyncio
import httpx
import telegram
from dotenv import load_dotenv
from typing import Dict, Optional
import threading
import time
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ConversationHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)
from azure.core.credentials import AzureKeyCredential
from azure.ai.documentintelligence.aio import DocumentIntelligenceClient
from azure.ai.documentintelligence.models import AnalyzeResult, DocumentTable
from google.generativeai.types import GenerationConfig, HarmCategory, HarmBlockThreshold
from google.cloud import storage

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
# –ó–∞–≥—Ä—É–∂–∞–µ–º .env.local –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –æ–±—ã—á–Ω—ã–π .env
if os.path.exists('.env.local'):
    load_dotenv('.env.local')
    print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω .env.local (–ª–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞)")
else:
    load_dotenv()
    print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω .env (—Å–µ—Ä–≤–µ—Ä)")

# API –ö–ª—é—á–∏
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL_NAME = os.getenv("GEMINI_MODEL_NAME", "gemini-1.5-pro-latest") # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ
AZURE_ENDPOINT = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT")
AZURE_KEY = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

# Google Cloud Storage
GCS_BUCKET = os.getenv("GCS_BUCKET")
PROMPT_VERSION = os.getenv("PROMPT_VERSION", "v1.0")

genai.configure(api_key=GEMINI_API_KEY)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - [%(levelname)s] - (%(name)s) - %(message)s",
)
logger = logging.getLogger(__name__)

# –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Railway: GCS credentials –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
if os.getenv("GOOGLE_APPLICATION_CREDENTIALS_JSON"):
    import tempfile
    import json
    try:
        credentials_json = os.getenv("GOOGLE_APPLICATION_CREDENTIALS_JSON")
        credentials = json.loads(credentials_json)
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f:
            json.dump(credentials, f)
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = f.name
        logger.info("‚úÖ GCS credentials loaded from environment variable")
    except Exception as e:
        logger.error(f"‚ùå Failed to load GCS credentials from environment: {e}")

# –û—Ç–∫–ª—é—á–∞–µ–º —Å–ø–∞–º HTTP –∑–∞–ø—Ä–æ—Å–æ–≤
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("telegram.ext._updater").setLevel(logging.WARNING)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
(SELECTING_ACTION, AWAITING_CONFIRMATION, AWAITING_MANUAL_PAGE, AWAITING_URL, AWAITING_FEEDBACK) = range(5)
TEMP_DIR = "temp_bot_files"
MAX_RETRIES = 3
FEEDBACK_TIMEOUT_SECONDS = 1800  # 30 –º–∏–Ω—É—Ç –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
pending_feedback_tasks: Dict[int, Dict] = {}

# --- –§—É–Ω–∫—Ü–∏–∏-–ø–æ–º–æ—â–Ω–∏–∫–∏ ---

def create_gemini_model(model_name: str = None) -> genai.GenerativeModel:
    """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å Gemini —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
    if model_name is None:
        model_name = GEMINI_MODEL_NAME
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }
    
    return genai.GenerativeModel(
        model_name=model_name,
        safety_settings=safety_settings
    )

def get_prompt(file_path: str) -> str:
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        logger.error(f"Prompt file not found: {file_path}")
        return ""

def create_ocr_correction_prompt(ocr_text: str) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ OCR –æ—à–∏–±–æ–∫, –∏—Å–ø–æ–ª—å–∑—É—è –ª–æ–≥–∏–∫—É –∏–∑ 2b_ocr_correction.py.
    """
    prompt = f"""
üîß –ó–ê–î–ê–ß–ê: –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –æ—à–∏–±–æ–∫ OCR –≤ —Ç–∞–±–ª–∏—Ü–µ –º–µ—Ç–∞–ª–ª–æ–ø—Ä–æ–∫–∞—Ç–∞

üìã –ò–°–•–û–î–ù–´–ô –¢–ï–ö–°–¢ OCR:
{ocr_text}

üéØ –¶–ï–õ–¨: –ò—Å–ø—Ä–∞–≤–∏—Ç—å —Ç–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ OCR —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã

‚ö° –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:

1. **–†–ê–ó–ú–ï–†–´ –ü–†–û–§–ò–õ–ï–ô:**
   - 20–ë1, 20–ëI, 20BI ‚Üí 20–®1 (–¥–≤—É—Ç–∞–≤—Ä —à–∏—Ä–æ–∫–æ–ø–æ–ª–æ—á–Ω—ã–π)
   - [16n, [16–ø ‚Üí 16–ø (—à–≤–µ–ª–ª–µ—Ä)  
   - [200, [120 ‚Üí 200, 120 (—à–≤–µ–ª–ª–µ—Ä)
   - C247 ‚Üí 24–£ (—à–≤–µ–ª–ª–µ—Ä —Å —É–∫–ª–æ–Ω–æ–º)
   - +5, s5 ‚Üí s5 (–ª–∏—Å—Ç —Ç–æ–ª—â–∏–Ω–æ–π 5–º–º)
   - nucm ‚Üí –ª–∏—Å—Ç (–ø—Ä–æ—Å–µ—á–Ω–æ-–≤—ã—Ç—è–∂–Ω–æ–π)
   
2. **–ú–ê–†–ö–ò –°–¢–ê–õ–ò:**
   - –°5, –°—Ç5 ‚Üí –°—Ç3 (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ OCR –æ—à–∏–±–∫–∏)
   - –°6 ‚Üí –°235 (–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç)
   - C255, C245, C275 ‚Üí –°255, –°245, –°275 (–ª–∞—Ç–∏–Ω—Å–∫–∞—è C ‚Üí –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∞—è –°)
   
3. **–ù–ê–ó–í–ê–ù–ò–Ø –ü–†–û–§–ò–õ–ï–ô:**
   - –î–≤—É—Ç–∞–≤—Ä—ã ‚Üí –î–≤—É—Ç–∞–≤—Ä—ã —Å—Ç–∞–ª—å–Ω—ã–µ –≥–æ—Ä—è—á–µ–∫–∞—Ç–∞–Ω–Ω—ã–µ
   - –®–≤–µ–ª–ª–µ—Ä—ã ‚Üí –®–≤–µ–ª–ª–µ—Ä—ã —Å—Ç–∞–ª—å–Ω—ã–µ –≥–æ—Ä—è—á–µ–∫–∞—Ç–∞–Ω–Ω—ã–µ
   - –£–≥–æ–ª–∫–∏ ‚Üí –£–≥–æ–ª–∫–∏ —Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∞–≤–Ω–æ–ø–æ–ª–æ—á–Ω—ã–µ
   - –õ–∏—Å—Ç—ã ‚Üí –õ–∏—Å—Ç—ã —Å—Ç–∞–ª—å–Ω—ã–µ –≥–æ—Ä—è—á–µ–∫–∞—Ç–∞–Ω–Ω—ã–µ

4. **–ú–ê–°–°–´ –ò –ö–û–õ–ò–ß–ï–°–¢–í–ê:**
   - –ò—Å–ø—Ä–∞–≤—å –æ—á–µ–≤–∏–¥–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ —á–∏—Å–ª–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1O ‚Üí 10)
   - –°–æ—Ö—Ä–∞–Ω–∏ –¥–µ—Å—è—Ç–∏—á–Ω—ã–µ –¥—Ä–æ–±–∏ –∫–∞–∫ –µ—Å—Ç—å
   
üö® –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
- –û—à–∏–±–∫–∏ OCR —á–∞—â–µ –≤ –ë–£–ö–í–ê–•, —Ü–∏—Ñ—Ä—ã –≤ 99% —Å–ª—É—á–∞–µ–≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ
- –°–æ—Ö—Ä–∞–Ω–∏ –í–°–Æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã (—Å—Ç—Ä–æ–∫–∏, —Å—Ç–æ–ª–±—Ü—ã, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
- –ù–ï –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —Ç–æ–ª—å–∫–æ –∏—Å–ø—Ä–∞–≤–ª—è–π –æ—à–∏–±–∫–∏
- –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü –∫–∞–∫ –µ—Å—Ç—å
- –ò—Å–ø—Ä–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ –û–ß–ï–í–ò–î–ù–´–ï –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

üìã –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã –¥–æ–ª–∂–Ω–∞ –æ—Å—Ç–∞—Ç—å—Å—è –∏–¥–µ–Ω—Ç–∏—á–Ω–æ–π –∏—Å—Ö–æ–¥–Ω–æ–π.

üîç –ù–ê–ß–ò–ù–ê–ô –ö–û–†–†–ï–ö–¶–ò–Æ:
"""
    return prompt

def table_to_html(table: DocumentTable) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ–±—ä–µ–∫—Ç —Ç–∞–±–ª–∏—Ü—ã –∏–∑ Azure –≤ HTML-—Å—Ç—Ä–æ–∫—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–æ—Å—Ç—É—é —Å–µ—Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É."""
    if not table.cells:
        return ""
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ—Ç–∫—É —Ç–∞–±–ª–∏—Ü—ã
    grid = [['' for _ in range(table.column_count)] for _ in range(table.row_count)]
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º —Å–µ—Ç–∫—É —Å–æ–¥–µ—Ä–∂–∏–º—ã–º —è—á–µ–µ–∫
    for cell in table.cells:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–Ω–¥–µ–∫—Å—ã –Ω–µ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ –ø—Ä–µ–¥–µ–ª—ã —Å–µ—Ç–∫–∏
        if cell.row_index < table.row_count and cell.column_index < table.column_count:
            grid[cell.row_index][cell.column_index] = cell.content or ''

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML
    html_parts = ['<table border="1">']
    for row in grid:
        html_parts.append('<tr>')
        for cell_content in row:
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º HTML-—Å—É—â–Ω–æ—Å—Ç–∏
            import html
            html_parts.append(f'<td>{html.escape(cell_content)}</td>')
        html_parts.append('</tr>')
    html_parts.append('</table>')
    
    return '\n'.join(html_parts)

def flatten_json_to_dataframe(data: dict) -> pd.DataFrame:
    flat_list = []
    unit = data.get("–µ–¥–∏–Ω–∏—Ü–∞_–∏–∑–º–µ—Ä–µ–Ω–∏—è", "–Ω–µ —É–∫–∞–∑–∞–Ω–∞")
    for profile, p_data in data.get("–ø—Ä–æ—Ñ–∏–ª–∏", {}).items():
        for steel, s_data in p_data.get("–º–∞—Ä–∫–∏_—Å—Ç–∞–ª–∏", {}).items():
            for size, z_data in s_data.get("—Ä–∞–∑–º–µ—Ä—ã", {}).items():
                # –ò–∑–º–µ–Ω–µ–Ω–æ: —Ç–µ–ø–µ—Ä—å –ø–µ—Ä–µ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫, –∞ –Ω–µ —Å–ª–æ–≤–∞—Ä—å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
                for e_data in z_data.get("—ç–ª–µ–º–µ–Ω—Ç—ã", []):
                    flat_list.append({
                        "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è": profile,
                        "–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏": steel,
                        "–†–∞–∑–º–µ—Ä –ø—Ä–æ—Ñ–∏–ª—è": size,
                        "–¢–∏–ø —ç–ª–µ–º–µ–Ω—Ç–∞": e_data.get("—Ç–∏–ø"), # –î–∞–Ω–Ω—ã–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è –≤ —Å–ø–∏—Å–∫–µ
                        "–ü–æ–∑–∏—Ü–∏–∏": ", ".join(map(str, e_data.get("–ø–æ–∑–∏—Ü–∏–∏", []))),
                        f"–ú–∞—Å—Å–∞, {unit}": e_data.get("–º–∞—Å—Å–∞"),
                    })
    return pd.DataFrame(flat_list)

async def run_gemini_with_fallback(html_content: str, user_id: int, chat) -> dict:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç Gemini —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –ø—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞—Ö"""
    logger.info(f"[USER_ID: {user_id}] - Starting Gemini processing with fallback strategy")
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
    try:
        logger.info(f"[USER_ID: {user_id}] - Fallback Strategy 1: Full content with disabled safety")
        prompt = get_prompt("extract_and_correct.txt")
        model = create_gemini_model()
        
        response = await run_gemini_with_retry(
            model, 
            prompt, 
            html_content, 
            user_id, 
            generation_config=GenerationConfig(response_mime_type="application/json")
        )
        
        json_data = json.loads(response.text)
        logger.info(f"[USER_ID: {user_id}] - ‚úÖ Strategy 1 successful!")
        return json_data
        
    except Exception as e1:
        logger.warning(f"[USER_ID: {user_id}] - Strategy 1 failed: {e1}")
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –£–∫–æ—Ä–æ—á–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (–ø–µ—Ä–≤—ã–µ 50% HTML)
        try:
            await chat.send_message("‚ö†Ô∏è **–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏...**\n\nüîÑ **–ü—Ä–∏–º–µ–Ω—è—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥**\n*–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–∞–Ω–Ω—ã–µ —á–∞—Å—Ç—è–º–∏*")
            
            logger.info(f"[USER_ID: {user_id}] - Fallback Strategy 2: Shortened content (50%)")
            shortened_content = html_content[:len(html_content)//2] + "\n</table>"
            
            response = await run_gemini_with_retry(
                model, 
                prompt, 
                shortened_content, 
                user_id, 
                generation_config=GenerationConfig(response_mime_type="application/json")
            )
            
            json_data = json.loads(response.text)
            logger.info(f"[USER_ID: {user_id}] - ‚úÖ Strategy 2 successful!")
            
            await chat.send_message("‚ö° **–ß–∞—Å—Ç–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞!**\n*–û–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –ø–µ—Ä–≤–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ –¥–∞–Ω–Ω—ã—Ö*")
            return json_data
            
        except Exception as e2:
            logger.warning(f"[USER_ID: {user_id}] - Strategy 2 failed: {e2}")
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –±–µ–∑ HTML —Ç–µ–≥–æ–≤
            try:
                await chat.send_message("üîß **–ü—Ä–∏–º–µ–Ω—è—é —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥...**\n\nüìÑ **–ò–∑–≤–ª–µ–∫–∞—é —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ**\n*–ë–µ–∑ HTML —Ä–∞–∑–º–µ—Ç–∫–∏*")
                
                logger.info(f"[USER_ID: {user_id}] - Fallback Strategy 3: Plain text only")
                
                # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
                import re
                plain_text = re.sub(r'<[^>]+>', ' ', html_content)
                plain_text = re.sub(r'\s+', ' ', plain_text).strip()
                
                # –£–∫–æ—Ä–æ—á–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                simple_prompt = f"""–ò–∑–≤–ª–µ–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–µ—Ç–∞–ª–ª–æ–ø—Ä–æ–∫–∞—Ç–∞ –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:

–¢–ï–ö–°–¢:
{plain_text[:3000]}...

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (JSON):
{{
  "–µ–¥–∏–Ω–∏—Ü–∞_–∏–∑–º–µ—Ä–µ–Ω–∏—è": "—Ç",
  "–ø—Ä–æ—Ñ–∏–ª–∏": {{
    "–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è": {{
      "–º–∞—Ä–∫–∏_—Å—Ç–∞–ª–∏": {{
        "–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏": {{
          "—Ä–∞–∑–º–µ—Ä—ã": {{
            "–†–∞–∑–º–µ—Ä": {{
              "—ç–ª–µ–º–µ–Ω—Ç—ã": [
                {{"—Ç–∏–ø": "–æ–ø–∏—Å–∞–Ω–∏–µ", "–ø–æ–∑–∏—Ü–∏–∏": ["1"], "–º–∞—Å—Å–∞": 0.0}}
              ]
            }}
          }}
        }}
      }}
    }}
  }}
}}

–ò–∑–≤–ª–µ–∫–∏ –º–∞–∫—Å–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""

                response = await run_gemini_with_retry(
                    model, 
                    simple_prompt, 
                    "", 
                    user_id, 
                    generation_config=GenerationConfig(response_mime_type="application/json")
                )
                
                json_data = json.loads(response.text)
                logger.info(f"[USER_ID: {user_id}] - ‚úÖ Strategy 3 successful!")
                
                await chat.send_message("‚úÖ **–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!**\n*–ò–∑–≤–ª–µ—á–µ–Ω—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ*")
                return json_data
                
            except Exception as e3:
                logger.error(f"[USER_ID: {user_id}] - All fallback strategies failed: {e3}")
                
                # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 4: –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ OCR
                await chat.send_message("üîÑ **–°–æ–∑–¥–∞—é –æ—Ç—á–µ—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ OCR**\n\nüìÑ **–í –æ—Ç—á–µ—Ç–µ –±—É–¥—É—Ç:**\n‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ Azure OCR\n‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ä—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏\n‚Ä¢ –í—Å–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ HTML –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
                import re
                plain_text = re.sub(r'<[^>]+>', '\n', html_content)
                lines = [line.strip() for line in plain_text.split('\n') if line.strip()]
                
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ö–æ—Ç—è –±—ã —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                numbers = re.findall(r'\d+[,.]?\d*', plain_text)
                
                fallback_data = {
                    "–µ–¥–∏–Ω–∏—Ü–∞_–∏–∑–º–µ—Ä–µ–Ω–∏—è": "—Ç",
                    "–ø—Ä–æ—Ñ–∏–ª–∏": {
                        "–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ OCR": {
                            "–º–∞—Ä–∫–∏_—Å—Ç–∞–ª–∏": {
                                "–¢—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏": {
                                    "—Ä–∞–∑–º–µ—Ä—ã": {
                                        "–í—Å–µ —Ä–∞–∑–º–µ—Ä—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞": {
                                            "—ç–ª–µ–º–µ–Ω—Ç—ã": [{
                                                "—Ç–∏–ø": f"OCR –¥–∞–Ω–Ω—ã–µ ({len(lines)} —Å—Ç—Ä–æ–∫, {len(numbers)} —á–∏—Å–µ–ª)",
                                                "–ø–æ–∑–∏—Ü–∏–∏": ["–í–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç"],
                                                "–º–∞—Å—Å–∞": sum([float(n.replace(',', '.')) for n in numbers[:10] if n.replace(',', '.').replace('.', '').isdigit()]) if numbers else 0.0
                                            }]
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
                
                logger.info(f"[USER_ID: {user_id}] - ‚úÖ Using fallback minimal data structure")
                return fallback_data

async def run_gemini_with_retry(model, prompt, content, user_id, generation_config=None):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç Gemini —Å retry –ª–æ–≥–∏–∫–æ–π. content –º–æ–∂–µ—Ç –±—ã—Ç—å —Ñ–∞–π–ª–æ–º –∏–ª–∏ —Ç–µ–∫—Å—Ç–æ–º"""
    retries = 0
    last_exception = None
    
    # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏ –∑–∞–ø—Ä–æ—Å–∞
    content_type = type(content).__name__
    prompt_length = len(prompt) if isinstance(prompt, str) else "N/A"
    has_gen_config = generation_config is not None
    
    logger.info(f"[USER_ID: {user_id}] - Starting Gemini API call:")
    logger.info(f"[USER_ID: {user_id}] - Model: {model.model_name}")
    logger.info(f"[USER_ID: {user_id}] - Content type: {content_type}")
    logger.info(f"[USER_ID: {user_id}] - Prompt length: {prompt_length}")
    logger.info(f"[USER_ID: {user_id}] - Has generation config: {has_gen_config}")
    if hasattr(content, 'name'):
        logger.info(f"[USER_ID: {user_id}] - File name: {content.name}")
    
    while retries < MAX_RETRIES:
        try:
            attempt_start = datetime.now()
            logger.info(f"[USER_ID: {user_id}] - Gemini API call attempt {retries + 1}/{MAX_RETRIES}")
            logger.info(f"[USER_ID: {user_id}] - Sending request to Gemini...")
            
            if generation_config:
                logger.info(f"[USER_ID: {user_id}] - Using generation config: {generation_config}")
                response = await model.generate_content_async([prompt, content], generation_config=generation_config)
            else:
                logger.info(f"[USER_ID: {user_id}] - Using default generation settings")
                response = await model.generate_content_async([prompt, content])
            
            attempt_duration = (datetime.now() - attempt_start).total_seconds()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–ª–∏ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
            if hasattr(response, 'prompt_feedback') and response.prompt_feedback:
                logger.info(f"[USER_ID: {user_id}] - Prompt feedback: {response.prompt_feedback}")
            
            if hasattr(response, 'candidates') and response.candidates:
                for i, candidate in enumerate(response.candidates):
                    if hasattr(candidate, 'finish_reason'):
                        finish_reason = candidate.finish_reason
                        logger.info(f"[USER_ID: {user_id}] - Candidate {i} finish reason: {finish_reason}")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏—á–∏–Ω—É –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (–Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º —Å—Ä–∞–∑—É)
                        if finish_reason == 1:  # SAFETY
                            logger.warning(f"[USER_ID: {user_id}] - Gemini –æ–±–Ω–∞—Ä—É–∂–∏–ª –ø—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (SAFETY), –Ω–æ –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∫–æ–Ω—Ç–µ–Ω—Ç")
                        elif finish_reason == 2:  # RECITATION
                            raise ValueError(f"Gemini –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑-–∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è (RECITATION)")
                        elif finish_reason == 3:  # OTHER
                            logger.warning(f"[USER_ID: {user_id}] - Gemini –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É –ø–æ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –ø—Ä–∏—á–∏–Ω–µ (OTHER)")
                        elif finish_reason == 4:  # MAX_TOKENS
                            logger.warning(f"[USER_ID: {user_id}] - –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ (MAX_TOKENS)")
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ—Ç–≤–µ—Ç–∞
            response_length = 0
            has_valid_response = False
            
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–µ–∫—Å—Ç –≤ –æ—Ç–≤–µ—Ç–µ –±–µ–∑ –≤—ã–∑–æ–≤–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
                if hasattr(response, 'candidates') and response.candidates:
                    for candidate in response.candidates:
                        if hasattr(candidate, 'content') and candidate.content:
                            if hasattr(candidate.content, 'parts') and candidate.content.parts:
                                for part in candidate.content.parts:
                                    if hasattr(part, 'text') and part.text:
                                        response_length = len(part.text)
                                        has_valid_response = True
                                        break
                        if has_valid_response:
                            break
                
                if has_valid_response:
                    logger.info(f"[USER_ID: {user_id}] - ‚úÖ Gemini API call successful!")
                    logger.info(f"[USER_ID: {user_id}] - Response time: {attempt_duration:.2f}s")
                    logger.info(f"[USER_ID: {user_id}] - Response length: {response_length} chars")
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, —ç—Ç–æ –æ—à–∏–±–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
                    logger.error(f"[USER_ID: {user_id}] - Gemini –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç")
                    raise ValueError("Gemini –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
                    
            except Exception as check_error:
                logger.error(f"[USER_ID: {user_id}] - –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ç–≤–µ—Ç–∞: {check_error}")
                raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {check_error}")
            
            return response
            
        except Exception as e:
            last_exception = e
            attempt_duration = (datetime.now() - attempt_start).total_seconds()
            
            logger.error(f"[USER_ID: {user_id}] - ‚ùå Gemini API call failed after {attempt_duration:.2f}s")
            logger.error(f"[USER_ID: {user_id}] - Error type: {type(e).__name__}")
            logger.error(f"[USER_ID: {user_id}] - Error message: {str(e)}")
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
            is_retryable = (
                "500" in str(e) or 
                "internal error" in str(e).lower() or
                "InternalServerError" in str(e) or
                "ServiceUnavailable" in str(e) or
                "TooManyRequests" in str(e) or
                "DeadlineExceeded" in str(e) or
                "timeout" in str(e).lower() or
                "connection" in str(e).lower()
            )
            
            if is_retryable and retries < MAX_RETRIES - 1:
                retries += 1
                wait_time = 5 * (2 ** (retries - 1))
                logger.warning(f"[USER_ID: {user_id}] - üîÑ Retryable error detected. Waiting {wait_time}s...")
                await asyncio.sleep(wait_time)
            else:
                logger.error(f"[USER_ID: {user_id}] - üö´ Non-retryable error or max retries reached")
                raise e
    
    logger.error(f"[USER_ID: {user_id}] - üí• All {MAX_RETRIES} retry attempts failed")
    raise last_exception

def convert_file_sharing_url(url: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Å—ã–ª–∫–∏ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫–æ–≤ –≤ –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.
    """
    # Google Drive
    if "drive.google.com" in url:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID —Ñ–∞–π–ª–∞ –∏–∑ —Å—Å—ã–ª–∫–∏
        match = re.search(r'/d/([a-zA-Z0-9-_]+)', url)
        if match:
            file_id = match.group(1)
            return f"https://drive.google.com/uc?export=download&id={file_id}"
    
    # –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫
    elif "disk.yandex" in url:
        # –î–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞ –Ω—É–∂–µ–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π API-–∑–∞–ø—Ä–æ—Å
        return url  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
    
    # Dropbox
    elif "dropbox.com" in url:
        # –ó–∞–º–µ–Ω—è–µ–º dl=0 –Ω–∞ dl=1 –¥–ª—è –ø—Ä—è–º–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        return url.replace("dl=0", "dl=1").replace("?dl=0", "?dl=1")
    
    # WeTransfer –∏ –¥—Ä—É–≥–∏–µ
    return url

async def download_file_from_url(url: str, user_id: int) -> bytes:
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –ø–æ —Å—Å—ã–ª–∫–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫–æ–≤.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Å—ã–ª–∫—É –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
    download_url = convert_file_sharing_url(url)
    
    async with httpx.AsyncClient(timeout=300.0, follow_redirects=True) as client:
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        try:
            head_response = await client.head(download_url, headers=headers)
            content_length = head_response.headers.get('content-length')
            if content_length and int(content_length) > 50 * 1024 * 1024:  # 50 MB –ª–∏–º–∏—Ç
                raise ValueError(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({int(content_length) / 1024 / 1024:.1f} –ú–ë). –ú–∞–∫—Å–∏–º—É–º 50 –ú–ë.")
        except Exception:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
            pass
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        response = await client.get(download_url, headers=headers)
        response.raise_for_status()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        if len(response.content) > 50 * 1024 * 1024:
            raise ValueError(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({len(response.content) / 1024 / 1024:.1f} –ú–ë). –ú–∞–∫—Å–∏–º—É–º 50 –ú–ë.")
        
        return response.content

def is_valid_file_url(text: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –≤–∞–ª–∏–¥–Ω–æ–π —Å—Å—ã–ª–∫–æ–π –Ω–∞ Dropbox.
    """
    url_pattern = r'https?://[^\s]+'
    if not re.match(url_pattern, text):
        return False
    
    return 'dropbox.com' in text.lower()

# --- Google Cloud Storage —Ñ—É–Ω–∫—Ü–∏–∏ ---

def prepare_telegram_image(page, user_id: int) -> io.BytesIO:
    """
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram
    —Å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    """
    # Telegram Photo API –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:
    # - –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: –¥–æ 10MB
    # - –†–∞–∑–º–µ—Ä—ã: –æ—Ç 10x10 –¥–æ 10000x10000 –ø–∏–∫—Å–µ–ª–µ–π
    # - –ù–æ –µ—Å—Ç—å –Ω–µ—è–≤–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω –∏ –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –ª–∏–º–∏—Ç—ã –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã
    MAX_WIDTH = 4096   # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ª–∏–º–∏—Ç –≤–º–µ—Å—Ç–æ 10000
    MAX_HEIGHT = 4096  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ª–∏–º–∏—Ç –≤–º–µ—Å—Ç–æ 10000 
    MAX_FILE_SIZE_MB = 8  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ª–∏–º–∏—Ç –≤–º–µ—Å—Ç–æ 10MB
    
    # –°–æ–∑–¥–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —É–º–µ—Ä–µ–Ω–Ω—ã–º DPI
    pix = page.get_pixmap(dpi=150)
    png_bytes = pix.tobytes("png")
    image = Image.open(io.BytesIO(png_bytes))
    
    original_width, original_height = image.size
    logger.info(f"[USER_ID: {user_id}] - Original image: {original_width}x{original_height}")
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –µ—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω—ã –ª–∏–º–∏—Ç—ã
    if original_width > MAX_WIDTH or original_height > MAX_HEIGHT:
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
        scale_factor = min(MAX_WIDTH / original_width, MAX_HEIGHT / original_height)
        new_width = int(original_width * scale_factor)
        new_height = int(original_height * scale_factor)
        
        image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        logger.info(f"[USER_ID: {user_id}] - Resized to: {new_width}x{new_height} (scale: {scale_factor:.2f})")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
    if image.width < 10 or image.height < 10:
        scale_factor = max(15 / image.width, 15 / image.height)
        new_width = int(image.width * scale_factor)
        new_height = int(image.height * scale_factor)
        image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        logger.info(f"[USER_ID: {user_id}] - Upscaled to meet minimum: {new_width}x{new_height}")
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º PNG
    img_buffer = io.BytesIO()
    image.save(img_buffer, format='PNG', optimize=True)
    img_buffer.seek(0)
    file_size_mb = len(img_buffer.getvalue()) / 1024 / 1024
    
    # –ï—Å–ª–∏ PNG —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JPEG
    if file_size_mb > MAX_FILE_SIZE_MB:
        logger.warning(f"[USER_ID: {user_id}] - PNG too large ({file_size_mb:.1f}MB), converting to JPEG")
        img_buffer = io.BytesIO()
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        for quality in [85, 75, 65, 55]:
            img_buffer = io.BytesIO()
            image.save(img_buffer, format='JPEG', quality=quality, optimize=True)
            img_buffer.seek(0)
            file_size_mb = len(img_buffer.getvalue()) / 1024 / 1024
            
            if file_size_mb <= MAX_FILE_SIZE_MB:
                logger.info(f"[USER_ID: {user_id}] - JPEG quality {quality}: {file_size_mb:.1f}MB")
                break
        
        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä
        if file_size_mb > MAX_FILE_SIZE_MB:
            scale_factor = 0.8
            new_width = int(image.width * scale_factor)
            new_height = int(image.height * scale_factor)
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            img_buffer = io.BytesIO()
            image.save(img_buffer, format='JPEG', quality=75, optimize=True)
            img_buffer.seek(0)
            file_size_mb = len(img_buffer.getvalue()) / 1024 / 1024
            logger.info(f"[USER_ID: {user_id}] - Final resize: {new_width}x{new_height}, {file_size_mb:.1f}MB")
    
    final_size_mb = len(img_buffer.getvalue()) / 1024 / 1024
    logger.info(f"[USER_ID: {user_id}] - Final Telegram image: {image.width}x{image.height}, {final_size_mb:.1f}MB")
    
    return img_buffer

def clean_filename(filename: str) -> str:
    """–û—á–∏—â–∞–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ GCS"""
    if not filename:
        return "unknown"
    
    # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
    name = os.path.splitext(filename)[0]
    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
    name = name.replace(" ", "_")
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∞–ª—Ñ–∞–≤–∏—Ç, —Ü–∏—Ñ—Ä—ã –∏ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
    name = re.sub(r'[^a-zA-Z–∞-—è—ë–ê-–Ø–Å0-9_]', '', name)
    
    return name or "unknown"

def format_utc_timestamp() -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ UTC –¥–ª—è –∏–º–µ–Ω–∏ –ø–∞–ø–∫–∏"""
    now = datetime.now(timezone.utc)
    # –§–æ—Ä–º–∞—Ç: 2025-08-02T14-30-45Z (–¥–≤–æ–µ—Ç–æ—á–∏—è –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ –¥–µ—Ñ–∏—Å—ã)
    return now.strftime("%Y-%m-%dT%H-%M-%SZ")

async def save_to_gcs_initial(
    user_id: int,
    pdf_name: str,
    page_image_bytes: bytes,
    ocr_html: str,
    corrected_json: dict,
    find_prompt: str,
    extract_prompt: str
) -> Optional[str]:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞—á–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ GCS –ë–ï–ó —Å–æ–∑–¥–∞–Ω–∏—è parquet
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç base_path –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    """
    if not GCS_BUCKET:
        logger.warning("GCS_BUCKET not configured, skipping initial save")
        return None
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç GCS
        client = storage.Client()
        bucket = client.bucket(GCS_BUCKET)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å
        timestamp = format_utc_timestamp()
        clean_pdf_name = clean_filename(pdf_name)
        base_path = f"user_{user_id}/{clean_pdf_name}_{timestamp}"
        
        logger.info(f"[USER_ID: {user_id}] - Initial save to GCS: {base_path}")
        
        # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º input.webp (–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WebP lossless)
        try:
            webp_buffer = io.BytesIO()
            image = Image.open(io.BytesIO(page_image_bytes))
            image.save(webp_buffer, format='WEBP', lossless=True)
            webp_bytes = webp_buffer.getvalue()
            
            blob = bucket.blob(f"{base_path}/input.webp")
            blob.upload_from_string(webp_bytes, content_type='image/webp')
        except Exception as img_error:
            # –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ PNG
            logger.warning(f"[USER_ID: {user_id}] - WebP conversion failed, saving as PNG: {img_error}")
            blob = bucket.blob(f"{base_path}/input.png")
            blob.upload_from_string(page_image_bytes, content_type='image/png')
        
        # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º ocr_raw.html.gz
        html_gzipped = gzip.compress(ocr_html.encode('utf-8'))
        blob = bucket.blob(f"{base_path}/ocr_raw.html.gz")
        blob.upload_from_string(html_gzipped, content_type='application/gzip')
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º corrected.json
        json_data = json.dumps(corrected_json, ensure_ascii=False, indent=2)
        blob = bucket.blob(f"{base_path}/corrected.json")
        blob.upload_from_string(json_data, content_type='application/json; charset=utf-8')
        
        # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º find_prompt.txt
        blob = bucket.blob(f"{base_path}/find_prompt.txt")
        blob.upload_from_string(find_prompt, content_type='text/plain; charset=utf-8')
        
        # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º extract_prompt.txt
        blob = bucket.blob(f"{base_path}/extract_prompt.txt")
        blob.upload_from_string(extract_prompt, content_type='text/plain; charset=utf-8')
        
        # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º meta.json (–ë–ï–ó feedback_status - –æ–Ω –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –ø–æ–∑–∂–µ)
        meta_data = {
            "user_id": user_id,
            "pdf_name": pdf_name,
            "clean_pdf_name": clean_pdf_name,
            "timestamp": timestamp,
            "timestamp_iso": datetime.now(timezone.utc).isoformat(),
            "find_prompt_length": len(find_prompt),
            "extract_prompt_length": len(extract_prompt),
            "processing_id": str(uuid.uuid4()),
            "feedback_status": "pending"  # –û–∂–∏–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        }
        meta_json = json.dumps(meta_data, ensure_ascii=False, indent=2)
        blob = bucket.blob(f"{base_path}/meta.json")
        blob.upload_from_string(meta_json, content_type='application/json; charset=utf-8')
        
        logger.info(f"[USER_ID: {user_id}] - Initial save successful: {base_path}")
        return base_path
        
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error in save_to_gcs_initial: {e}", exc_info=True)
        return None

def schedule_feedback_timeout(user_id: int, base_path: str, timeout_seconds: int = 1800):
    """
    –ü–ª–∞–Ω–∏—Ä—É–µ—Ç –∑–∞–¥–∞—á—É –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É timeout –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ (30 –º–∏–Ω—É—Ç)
    """
    def timeout_handler():
        time.sleep(timeout_seconds)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞–¥–∞—á–∞ –Ω–µ –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞
        if user_id in pending_feedback_tasks and not pending_feedback_tasks[user_id].get("cancel", False):
            logger.info(f"[USER_ID: {user_id}] - Feedback timeout reached, finalizing with 'timeout'")
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—é –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(finalize_gcs_entry(base_path, "timeout"))
            loop.close()
            # –£–¥–∞–ª—è–µ–º –∑–∞–¥–∞—á—É –∏–∑ pending
            pending_feedback_tasks.pop(user_id, None)
    
    # –û—Ç–º–µ–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –∑–∞–¥–∞—á—É –µ—Å–ª–∏ –µ—Å—Ç—å
    if user_id in pending_feedback_tasks:
        pending_feedback_tasks[user_id]["cancel"] = True
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
    pending_feedback_tasks[user_id] = {
        "base_path": base_path,
        "cancel": False,
        "started_at": datetime.now(timezone.utc)
    }
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    thread = threading.Thread(target=timeout_handler, daemon=True)
    thread.start()
    
    logger.info(f"[USER_ID: {user_id}] - Scheduled feedback timeout in {timeout_seconds//60} minutes")

async def finalize_gcs_entry(base_path: str, feedback_status: str):
    """
    –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø–∏—Å—å –≤ GCS: –æ–±–Ω–æ–≤–ª—è–µ—Ç meta.json –∏ —Å–æ–∑–¥–∞–µ—Ç parquet
    feedback_status: 'good', 'bad', –∏–ª–∏ 'timeout'
    """
    if not GCS_BUCKET:
        logger.warning("GCS_BUCKET not configured, skipping finalization")
        return
    
    try:
        client = storage.Client()
        bucket = client.bucket(GCS_BUCKET)
        
        logger.info(f"Finalizing GCS entry: {base_path} with feedback: {feedback_status}")
        
        # 1. –û–±–Ω–æ–≤–ª—è–µ–º meta.json —Å feedback_status
        meta_blob = bucket.blob(f"{base_path}/meta.json")
        if meta_blob.exists():
            meta_data = json.loads(meta_blob.download_as_text())
            meta_data["feedback_status"] = feedback_status
            meta_data["feedback_received_at"] = datetime.now(timezone.utc).isoformat()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π meta.json
            meta_json = json.dumps(meta_data, ensure_ascii=False, indent=2)
            meta_blob.upload_from_string(meta_json, content_type='application/json; charset=utf-8')
        else:
            logger.error(f"Meta.json not found at {base_path}/meta.json")
            return
        
        # 2. –°–æ–∑–¥–∞–µ–º feedback.txt
        feedback_messages = {
            "good": f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–≤–æ–ª–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏\n–í—Ä–µ–º—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏: {datetime.now(timezone.utc).isoformat()}",
            "bad": f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ù–ï –¥–æ–≤–æ–ª–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏\n–í—Ä–µ–º—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏: {datetime.now(timezone.utc).isoformat()}\n–ö–æ–Ω—Ç–∞–∫—Ç –∞–¥–º–∏–Ω–∞: @aianback",
            "timeout": f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å (timeout)\n–í—Ä–µ–º—è –∏—Å—Ç–µ—á–µ–Ω–∏—è: {datetime.now(timezone.utc).isoformat()}"
        }
        
        feedback_blob = bucket.blob(f"{base_path}/feedback.txt")
        feedback_blob.upload_from_string(
            feedback_messages.get(feedback_status, "Unknown feedback status"), 
            content_type='text/plain; charset=utf-8'
        )
        
        # 3. –°–æ–∑–¥–∞–µ–º parquet –∑–∞–ø–∏—Å—å
        await create_parquet_entry(base_path, meta_data, feedback_status)
        
        logger.info(f"Successfully finalized GCS entry: {base_path}")
        
    except Exception as e:
        logger.error(f"Error finalizing GCS entry {base_path}: {e}", exc_info=True)

async def create_parquet_entry(base_path: str, meta_data: dict, feedback_status: str):
    """
    –°–æ–∑–¥–∞–µ—Ç –∑–∞–ø–∏—Å—å –≤ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–º parquet —Ñ–∞–π–ª–µ
    """
    try:
        if not GCS_BUCKET:
            return
            
        client = storage.Client()
        bucket = client.bucket(GCS_BUCKET)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
        parquet_path = f"dataset/{today}.parquet"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º corrected.json –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        corrected_blob = bucket.blob(f"{base_path}/corrected.json")
        if corrected_blob.exists():
            corrected_data = json.loads(corrected_blob.download_as_text())
        else:
            corrected_data = {}
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ—Ñ–∏–ª–µ–π
        profiles_count = 0
        total_mass = 0.0
        profile_types = set()
        
        if "–ø—Ä–æ—Ñ–∏–ª–∏" in corrected_data:
            for profile_name, profile_data in corrected_data["–ø—Ä–æ—Ñ–∏–ª–∏"].items():
                profiles_count += 1
                profile_types.add(profile_name)
                if isinstance(profile_data, dict) and "–º–∞—Ä–∫–∏_—Å—Ç–∞–ª–∏" in profile_data:
                    for steel_grade, steel_data in profile_data["–º–∞—Ä–∫–∏_—Å—Ç–∞–ª–∏"].items():
                        if isinstance(steel_data, dict) and "—Ä–∞–∑–º–µ—Ä—ã" in steel_data:
                            for size_name, size_data in steel_data["—Ä–∞–∑–º–µ—Ä—ã"].items():
                                if isinstance(size_data, dict) and "—ç–ª–µ–º–µ–Ω—Ç—ã" in size_data:
                                    for element in size_data["—ç–ª–µ–º–µ–Ω—Ç—ã"]:
                                        if isinstance(element, dict) and "–º–∞—Å—Å–∞" in element:
                                            try:
                                                total_mass += float(element["–º–∞—Å—Å–∞"])
                                            except (ValueError, TypeError):
                                                pass
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –¥–ª—è parquet
        record = {
            "timestamp": meta_data.get("timestamp_iso", datetime.now(timezone.utc).isoformat()),
            "user_id": meta_data.get("user_id", 0),
            "pdf_name": meta_data.get("pdf_name", "unknown"),
            "processing_id": meta_data.get("processing_id", str(uuid.uuid4())),
            "feedback_status": feedback_status,
            "profiles_found": profiles_count,
            "total_mass_tons": round(total_mass, 3),
            "unique_profile_types": len(profile_types),
            "find_prompt_length": meta_data.get("find_prompt_length", 0),
            "extract_prompt_length": meta_data.get("extract_prompt_length", 0),
            "gcs_path": base_path
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ parquet —Ñ–∞–π–ª –∑–∞ —Å–µ–≥–æ–¥–Ω—è
        parquet_blob = bucket.blob(parquet_path)
        
        if parquet_blob.exists():
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
            parquet_buffer = io.BytesIO()
            parquet_blob.download_to_file(parquet_buffer)
            parquet_buffer.seek(0)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ —á—Ç–µ–Ω–∏–µ–º
            parquet_size = len(parquet_buffer.getvalue())
            
            if parquet_size > 0:
                # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
                existing_df = pd.read_parquet(parquet_buffer)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
                new_df = pd.DataFrame([record])
                combined_df = pd.concat([existing_df, new_df], ignore_index=True)
            else:
                # –ü—É—Å—Ç–æ–π —Ñ–∞–π–ª - —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame
                combined_df = pd.DataFrame([record])
        else:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame
            combined_df = pd.DataFrame([record])
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π parquet
        parquet_buffer = io.BytesIO()
        combined_df.to_parquet(parquet_buffer, index=False)
        parquet_buffer.seek(0)
        
        parquet_blob.upload_from_file(parquet_buffer, content_type='application/octet-stream')
        
        logger.info(f"Updated parquet dataset: {parquet_path} (total records: {len(combined_df)})")
        
    except Exception as e:
        logger.error(f"Error creating parquet entry: {e}", exc_info=True)

async def save_to_gcs(
    user_id: int,
    pdf_name: str,
    page_image_bytes: bytes,
    ocr_html: str,
    corrected_json: dict,
    find_prompt: str,
    extract_prompt: str,
    user_satisfied: str = "unknown"
) -> bool:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤ Google Cloud Storage –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    if not GCS_BUCKET:
        logger.warning("GCS_BUCKET not configured, skipping archive")
        return False
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç GCS
        client = storage.Client()
        bucket = client.bucket(GCS_BUCKET)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å
        timestamp = format_utc_timestamp()
        clean_pdf_name = clean_filename(pdf_name)
        base_path = f"user_{user_id}/{clean_pdf_name}_{timestamp}"
        
        logger.info(f"[USER_ID: {user_id}] - Saving to GCS: {base_path}")
        
        # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º input.webp (–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WebP lossless)
        webp_buffer = io.BytesIO()
        image = Image.open(io.BytesIO(page_image_bytes))
        image.save(webp_buffer, format='WEBP', lossless=True)
        webp_bytes = webp_buffer.getvalue()
        
        blob = bucket.blob(f"{base_path}/input.webp")
        blob.upload_from_string(webp_bytes, content_type='image/webp')
        
        # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º ocr_raw.html.gz
        html_gzipped = gzip.compress(ocr_html.encode('utf-8'))
        blob = bucket.blob(f"{base_path}/ocr_raw.html.gz")
        blob.upload_from_string(html_gzipped, content_type='application/gzip')
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º corrected.json
        json_data = json.dumps(corrected_json, ensure_ascii=False, indent=2)
        blob = bucket.blob(f"{base_path}/corrected.json")
        blob.upload_from_string(json_data, content_type='application/json; charset=utf-8')
        
        # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º find_prompt.txt (–ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–∞–±–ª–∏—Ü)
        blob = bucket.blob(f"{base_path}/find_prompt.txt")
        blob.upload_from_string(find_prompt, content_type='text/plain; charset=utf-8')
        
        # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º extract_prompt.txt (–ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö)
        blob = bucket.blob(f"{base_path}/extract_prompt.txt")
        blob.upload_from_string(extract_prompt, content_type='text/plain; charset=utf-8')
        
        # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º meta.json
        meta_data = {
            "user_id": user_id,
            "pdf_name": pdf_name,
            "clean_pdf_name": clean_pdf_name,
            "timestamp": timestamp,
            "timestamp_iso": datetime.now(timezone.utc).isoformat(),
            "find_prompt_length": len(find_prompt),
            "extract_prompt_length": len(extract_prompt),
            "processing_id": str(uuid.uuid4()),
            "user_satisfied": user_satisfied
        }
        meta_json = json.dumps(meta_data, ensure_ascii=False, indent=2)
        blob = bucket.blob(f"{base_path}/meta.json")
        blob.upload_from_string(meta_json, content_type='application/json; charset=utf-8')
        
        # 7. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
        if user_satisfied == "yes":
            feedback_content = f"User satisfied with processing\nTimestamp: {timestamp}\nPDF: {pdf_name}"
            blob = bucket.blob(f"{base_path}/good.txt")
            blob.upload_from_string(feedback_content, content_type='text/plain; charset=utf-8')
        elif user_satisfied == "no":
            feedback_content = f"User NOT satisfied with processing\nTimestamp: {timestamp}\nPDF: {pdf_name}\nContact admin: @aianback"
            blob = bucket.blob(f"{base_path}/bad.txt")
            blob.upload_from_string(feedback_content, content_type='text/plain; charset=utf-8')
        
        logger.info(f"[USER_ID: {user_id}] - Successfully saved to GCS: {base_path}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—É—Ç–æ—á–Ω—ã–π Parquet (async task)
        asyncio.create_task(add_to_daily_parquet(
            user_id, clean_pdf_name, webp_bytes, ocr_html, corrected_json, find_prompt, extract_prompt
        ))
        
        return True
        
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Failed to save to GCS: {e}", exc_info=True)
        return False


async def add_to_daily_parquet(
    user_id: int,
    pdf_name: str, 
    webp_bytes: bytes,
    ocr_html: str,
    corrected_json: dict,
    find_prompt: str,
    extract_prompt: str
):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–ø–∏—Å—å –≤ —Å—É—Ç–æ—á–Ω—ã–π Parquet —Ñ–∞–π–ª
    """
    if not GCS_BUCKET:
        return
        
    try:
        client = storage.Client()
        bucket = client.bucket(GCS_BUCKET)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–µ–≥–æ–¥–Ω—è
        today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
        parquet_path = f"dataset/{today}.parquet"
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
        new_record = {
            "png_webp": [webp_bytes],
            "ocr_html": [ocr_html],
            "corrected": [json.dumps(corrected_json, ensure_ascii=False)],
            "find_prompt": [find_prompt],
            "extract_prompt": [extract_prompt],
            "user_id": [user_id],
            "pdf_name": [pdf_name],
            "ts": [datetime.now(timezone.utc)]
        }
        
        new_df = pd.DataFrame(new_record)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ñ–∞–π–ª
        blob = bucket.blob(parquet_path)
        
        if blob.exists():
            # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
            existing_data = blob.download_as_bytes()
            existing_df = pd.read_parquet(io.BytesIO(existing_data))
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            combined_df = pd.concat([existing_df, new_df], ignore_index=True)
        else:
            combined_df = new_df
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ
        parquet_buffer = io.BytesIO()
        combined_df.to_parquet(parquet_buffer, compression='zstd', index=False)
        parquet_buffer.seek(0)
        
        blob.upload_from_file(parquet_buffer, content_type='application/octet-stream')
        
        logger.info(f"[USER_ID: {user_id}] - Added to daily parquet: {parquet_path}")
        
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Failed to add to parquet: {e}", exc_info=True)

# --- –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ --- 

async def process_specification(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat = update.effective_chat
    user_id = update.effective_user.id
    try:
        pdf_bytes = context.user_data["pdf_bytes"]
        page_number = context.user_data.get("manual_page_number") or context.user_data.get("found_page_number")

        # –≠—Ç–∞–ø 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ PNG –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å Azure
        logger.info(f"[USER_ID: {user_id}] - STEP 2: Extracting page {page_number} to PNG and sending to Azure...")
        
        step2_message = f"""‚öôÔ∏è –≠—Ç–∞–ø 2/4: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞

üì∑ –ò–∑–≤–ª–µ–∫–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_number} –≤ –≤—ã—Å–æ–∫–æ–º –∫–∞—á–µ—Å—Ç–≤–µ...
üîç –û—Ç–ø—Ä–∞–≤–ª—è—é –≤ Azure OCR –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...

*–û–ø—Ä–µ–¥–µ–ª—è—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü –∏ –∏–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç*"""
        
        await chat.send_message(step2_message)
        pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if page_number > len(pdf_document):
            pdf_document.close()
            await chat.send_message(f"–û—à–∏–±–∫–∞: —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –î–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ {len(pdf_document)} —Å—Ç—Ä–∞–Ω–∏—Ü.")
            return
        
        page_to_ocr = pdf_document.load_page(page_number - 1)
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å DPI 300, –Ω–æ —É–º–µ–Ω—å—à–∞–µ–º –µ—Å–ª–∏ —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
        dpi = 300
        max_file_size = 4 * 1024 * 1024  # 4MB –ª–∏–º–∏—Ç –¥–ª—è Azure
        
        while dpi >= 150:
            pix = page_to_ocr.get_pixmap(dpi=dpi)
            png_bytes = pix.tobytes("png")
            
            if len(png_bytes) <= max_file_size:
                logger.info(f"[USER_ID: {user_id}] - Using DPI {dpi}, image size: {len(png_bytes) / 1024 / 1024:.1f}MB")
                break
            else:
                logger.warning(f"[USER_ID: {user_id}] - DPI {dpi} too large ({len(png_bytes) / 1024 / 1024:.1f}MB), reducing...")
                dpi -= 50
        
        if len(png_bytes) > max_file_size:
            pdf_document.close()
            await chat.send_message("–û—à–∏–±–∫–∞: —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å –¥—Ä—É–≥–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º.")
            return
            
        pdf_document.close()

        async with DocumentIntelligenceClient(endpoint=AZURE_ENDPOINT, credential=AzureKeyCredential(AZURE_KEY)) as client:
            poller = await client.begin_analyze_document("prebuilt-layout", png_bytes, content_type="application/octet-stream")
            result = await poller.result()
        if not result.tables:
            await chat.send_message("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–∞–±–ª–∏—Ü—É –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ.")
            return

        # --- –û–±—ä–µ–¥–∏–Ω—è–µ–º –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –≤ –æ–¥–∏–Ω HTML –¥–ª—è Gemini ---
        all_tables_html_parts = [table_to_html(table) for table in result.tables]
        full_html_content = "\n<hr>\n".join(all_tables_html_parts) # –°–æ–µ–¥–∏–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—ã –ª–∏–Ω–∏–µ–π
        logger.info(f"[USER_ID: {user_id}] - Combined HTML from {len(result.tables)} tables generated for Gemini.")

        # --- –û–¢–õ–ê–î–ö–ê: –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç—Ç–æ—Ç –∂–µ HTML –≤ —Ñ–∞–π–ª ---
        debug_file_path = os.path.join(TEMP_DIR, f"azure_output_{user_id}.html")
        with open(debug_file_path, "w", encoding="utf-8") as f:
            f.write(full_html_content)
        logger.info(f"[USER_ID: {user_id}] - Azure OCR debug HTML saved to {debug_file_path}")
        # --- –ö–û–ù–ï–¶ –û–¢–õ–ê–î–ö–ò ---

        # –≠—Ç–∞–ø 3: –ï–¥–∏–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON
        logger.info(f"[USER_ID: {user_id}] - STEP 3: Correcting and extracting JSON with Gemini...")
        
        step3_message = """ü§ñ –≠—Ç–∞–ø 3/4: –ò–ò –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

‚ú® –ò—Å–ø—Ä–∞–≤–ª—è—é –æ—à–∏–±–∫–∏ OCR —Å –ø–æ–º–æ—â—å—é Gemini...
üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç JSON...
üîß –ü—Ä–∏–º–µ–Ω—è—é –ø—Ä–∞–≤–∏–ª–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –º–µ—Ç–∞–ª–ª–æ–ø—Ä–æ–∫–∞—Ç–∞...

*–≠—Ç–æ —Å–∞–º—ã–π —Å–ª–æ–∂–Ω—ã–π —ç—Ç–∞–ø, –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã*"""
        
        await chat.send_message(step3_message)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
        json_data = await run_gemini_with_fallback(full_html_content, user_id, chat)
        logger.info(f"[USER_ID: {user_id}] - JSON extracted successfully.")

        # --- –û–¢–õ–ê–î–ö–ê: –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é ---
        json_file_path = os.path.join(TEMP_DIR, f"structured_output_{user_id}.json")
        with open(json_file_path, "w", encoding="utf-8") as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        logger.info(f"[USER_ID: {user_id}] - JSON structured data saved to {json_file_path}")
        # --- –ö–û–ù–ï–¶ –û–¢–õ–ê–î–ö–ò JSON ---

        # –≠—Ç–∞–ø 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
        step4_message = """üìà –≠—Ç–∞–ø 4/4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤

üìä –°–æ–∑–¥–∞—é Excel —Ç–∞–±–ª–∏—Ü—É...
üìÑ –§–æ—Ä–º–∏—Ä—É—é —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç...
üíæ –°–æ—Ö—Ä–∞–Ω—è—é –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞—Ä—Ö–∏–≤–∞...

*–ü–æ—á—Ç–∏ –≥–æ—Ç–æ–≤–æ!*"""
        
        await chat.send_message(step4_message)
        
        df = flatten_json_to_dataframe(json_data)
        txt_buffer = io.BytesIO(df.to_string(index=False).encode('utf-8'))
        xlsx_buffer = io.BytesIO()
        df.to_excel(xlsx_buffer, index=False, engine='openpyxl')
        xlsx_buffer.seek(0)

        # –≠—Ç–∞–ø 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Google Cloud Storage –¥–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞
        pdf_file_name = context.user_data.get("pdf_file_name", "unknown")
        logger.info(f"[USER_ID: {user_id}] - STEP 5: Saving to GCS for fine-tuning...")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç—ã –∏–∑ —Ñ–∞–π–ª–æ–≤
        find_prompt = get_prompt("find_and_validate.txt")
        extract_prompt = get_prompt("extract_and_correct.txt")
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è (DPI 300)
        pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
        page_for_archive = pdf_document.load_page(page_number - 1)
        archive_pix = page_for_archive.get_pixmap(dpi=300)  # –í—Å–µ–≥–¥–∞ –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –∞—Ä—Ö–∏–≤–∞
        archive_png_bytes = archive_pix.tobytes("png")
        pdf_document.close()
        
        logger.info(f"[USER_ID: {user_id}] - Archive image: {len(archive_png_bytes) / 1024 / 1024:.1f}MB at 300 DPI")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ GCS –ë–ï–ó —Å–æ–∑–¥–∞–Ω–∏—è parquet (–æ–Ω –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –ø–æ—Å–ª–µ feedback)
        base_path = await save_to_gcs_initial(
            user_id=user_id,
            pdf_name=pdf_file_name,
            page_image_bytes=archive_png_bytes,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ä—Ö–∏–≤–Ω—É—é –≤–µ—Ä—Å–∏—é!
            ocr_html=full_html_content,
            corrected_json=json_data,
            find_prompt=find_prompt,
            extract_prompt=extract_prompt
        )
        
        # –ü–ª–∞–Ω–∏—Ä—É–µ–º timeout –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        if base_path:
            schedule_feedback_timeout(user_id, base_path, FEEDBACK_TIMEOUT_SECONDS)

        success_message = """üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!

üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:
‚Ä¢ ‚úÖ –î–∞–Ω–Ω—ã–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω—ã
‚Ä¢ ‚úÖ –û—à–∏–±–∫–∏ OCR –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
‚Ä¢ ‚úÖ –°–æ–∑–¥–∞–Ω—ã –æ—Ç—á–µ—Ç—ã –≤ –¥–≤—É—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö

üìÅ –ü–æ–ª—É—á–∏—Ç–µ –≤–∞—à–∏ —Ñ–∞–π–ª—ã:"""

        await chat.send_message(success_message)
        await chat.send_document(
            document=InputFile(xlsx_buffer, filename="specification.xlsx"),
            caption="üìà Excel —Ñ–∞–π–ª - –≥–æ—Ç–æ–≤ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö"
        )
        await chat.send_document(
            document=InputFile(txt_buffer, filename="specification.txt"), 
            caption="üìÑ –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª - –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è"
        )
        
        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ OCR
        if "–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ OCR" in str(json_data):
            try:
                ocr_buffer = io.BytesIO(full_html_content.encode('utf-8'))
                await chat.send_document(
                    document=InputFile(ocr_buffer, filename="ocr_raw_data.html"),
                    caption="üîß **–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ OCR** - –¥–ª—è —Ä—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–æ—Ç–∫—Ä–æ–π—Ç–µ –≤ –±—Ä–∞—É–∑–µ—Ä–µ)"
                )
            except Exception:
                pass
        logger.info(f"[USER_ID: {user_id}] - FINAL: Reports sent.")
        
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        feedback_keyboard = [
            [InlineKeyboardButton("üëç –î–∞, –≤—Å—ë –æ—Ç–ª–∏—á–Ω–æ!", callback_data="feedback_yes")],
            [InlineKeyboardButton("üëé –ï—Å—Ç—å –æ—à–∏–±–∫–∏", callback_data="feedback_no")]
        ]
        feedback_message = """üìù –í—ã –¥–æ–≤–æ–ª—å–Ω—ã –∫–∞—á–µ—Å—Ç–≤–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏?

–í–∞—à –æ—Ç–∑—ã–≤ –ø–æ–º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤!

‚Ä¢ üëç –î–∞ - –µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞—Å —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç
‚Ä¢ üëé –ï—Å—Ç—å –æ—à–∏–±–∫–∏ - –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏ –∏–ª–∏ –æ—à–∏–±–∫–∏

–ü—Ä–∏ –≤—ã–±–æ—Ä–µ "–ï—Å—Ç—å –æ—à–∏–±–∫–∏" –≤—ã —Å–º–æ–∂–µ—Ç–µ —Å–≤—è–∑–∞—Ç—å—Å—è —Å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º."""
        
        await chat.send_message(
            feedback_message,
            reply_markup=InlineKeyboardMarkup(feedback_keyboard)
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ (–≤–∫–ª—é—á–∞—è base_path)
        context.user_data["processed_files"] = {
            "user_id": user_id,
            "pdf_name": pdf_file_name,
            "page_image_bytes": archive_png_bytes,
            "ocr_html": full_html_content,
            "corrected_json": json_data,
            "find_prompt": find_prompt,
            "extract_prompt": extract_prompt,
            "base_path": base_path  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
        }
        
        return AWAITING_FEEDBACK

    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error in process_specification: {e}", exc_info=True)
        await chat.send_message("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ.")
        return ConversationHandler.END

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_message = """ü§ñ –ü—Ä–∏–≤–µ—Ç! –Ø –≤–∞—à –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π –º–µ—Ç–∞–ª–ª–æ–ø—Ä–æ–∫–∞—Ç–∞!

‚ú® –ß—Ç–æ —è —É–º–µ—é:
‚Ä¢ üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é PDF –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –ø–æ–º–æ—â—å—é –ò–ò
‚Ä¢ üìä –ò–∑–≤–ª–µ–∫–∞—é —Ç–∞–±–ª–∏—Ü—ã —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π
‚Ä¢ ‚úÖ –ò—Å–ø—Ä–∞–≤–ª—è—é –æ—à–∏–±–∫–∏ OCR –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏  
‚Ä¢ üìà –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç—á–µ—Ç—ã –≤ Excel –∏ TXT

üìé –ó–∞–≥—Ä—É–∑–∏—Ç–µ PDF-—Ñ–∞–π–ª (–¥–æ 20 –ú–ë) –∏–ª–∏ 
üîó –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É —Å Dropbox

üí° –°–æ–≤–µ—Ç: –î–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Dropbox: https://dropbox.com

üöÄ –ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ! –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –¥–æ–∫—É–º–µ–Ω—Ç!"""
    
    await update.message.reply_text(welcome_message)
    return SELECTING_ACTION

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    
    if not update.message.document:
        return

    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ –ü–ï–†–ï–î —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ–º ---
    if update.message.document.file_size > 20 * 1024 * 1024: # 20 MB limit
        file_size_mb = update.message.document.file_size / 1024 / 1024
        logger.warning(f"[USER_ID: {user_id}] - PDF rejected: file too large ({file_size_mb:.2f} MB).")
        
        # –ö—Ä–∞—Å–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        message = f"""üìÅ –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({file_size_mb:.1f} –ú–ë)

üö´ Telegram –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Ñ–∞–π–ª—ã –¥–æ 20 –ú–ë
‚úÖ –ù–æ –º—ã –º–æ–∂–µ–º –ø–æ–º–æ—á—å!

üîó **–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –Ω–∞ Dropbox:**
üëâ https://dropbox.com

üì§ **–ó–∞—Ç–µ–º –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Å—Å—ã–ª–∫—É** –∏ —è –æ–±—Ä–∞–±–æ—Ç–∞—é –≤–∞—à –¥–æ–∫—É–º–µ–Ω—Ç

üí° **–°–æ–≤–µ—Ç:** –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å—Å—ã–ª–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∞ –¥–ª—è –æ–±—â–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞

üëá **–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É —Å Dropbox –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å:**"""

        await update.message.reply_text(message)
        return AWAITING_URL

    file_id = update.message.document.file_id
    file_name = update.message.document.file_name
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ GCS  
    context.user_data["pdf_file_name"] = file_name
    
    loading_message = f"""üì• –§–∞–π–ª –ø—Ä–∏–Ω—è—Ç! 

üìÑ –ò–º—è: `{file_name}`
üìä –†–∞–∑–º–µ—Ä: {update.message.document.file_size / 1024 / 1024:.1f} –ú–ë

‚è≥ –ó–∞–≥—Ä—É–∂–∞—é –¥–æ–∫—É–º–µ–Ω—Ç... 
*–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥*"""
    
    await update.message.reply_text(loading_message)

    try:
        file_info = await context.bot.get_file(file_id)
        
        file_url = file_info.file_path

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º httpx –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –ø–æ—Ç–æ–∫–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        async with httpx.AsyncClient() as client:
            async with client.stream("GET", file_url) as response:
                response.raise_for_status() # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫–∏ HTTP
                
                pdf_bytes_io = io.BytesIO()
                async for chunk in response.aiter_bytes():
                    pdf_bytes_io.write(chunk)
                pdf_bytes_io.seek(0)
                pdf_bytes = pdf_bytes_io.read()

        context.user_data["pdf_bytes"] = pdf_bytes
        logger.info(f"[USER_ID: {user_id}] - File '{file_name}' downloaded successfully.")

    except telegram.error.BadRequest as e:
        logger.error(f"[USER_ID: {user_id}] - Error getting file info: {e}", exc_info=True)
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ: {e}")
        return ConversationHandler.END
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error downloading file: {e}", exc_info=True)
        await update.message.reply_text(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞.")
        return ConversationHandler.END

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
    try:
        pdf_document_for_check = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
        num_pages = len(pdf_document_for_check)
        pdf_document_for_check.close()
        if num_pages > 100:
            logger.warning(f"[USER_ID: {user_id}] - PDF rejected: too many pages ({num_pages}).")
            await update.message.reply_text(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({num_pages} —Å—Ç—Ä–∞–Ω–∏—Ü). –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –Ω–µ –±–æ–ª–µ–µ 100 —Å—Ç—Ä–∞–Ω–∏—Ü.")
            return ConversationHandler.END
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Failed to check PDF page count: {e}")
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ PDF. –§–∞–π–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω.")
        return ConversationHandler.END

    analysis_message = """‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!

üîç –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞...
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—è—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
‚Ä¢ –ò—â—É —Ç–∞–±–ª–∏—Ü—ã —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π  
‚Ä¢ –û–ø—Ä–µ–¥–µ–ª—è—é –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏

ü§ñ –ò–ò –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞... 
*–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ 10-30 —Å–µ–∫—É–Ω–¥*"""
    
    await update.message.reply_text(analysis_message)

    temp_pdf_path = None
    try:
        os.makedirs(TEMP_DIR, exist_ok=True)
        temp_pdf_path = os.path.join(TEMP_DIR, f"{user_id}_check.pdf")
        with open(temp_pdf_path, "wb") as f:
            f.write(pdf_bytes)

        logger.info(f"[USER_ID: {user_id}] - STEP 1: Performing validation and page search with Gemini.")
        gemini_file = genai.upload_file(path=temp_pdf_path)
        prompt = get_prompt("find_and_validate.txt")
        model = create_gemini_model()
        
        response = await run_gemini_with_retry(model, prompt, gemini_file, user_id)
        genai.delete_file(gemini_file.name)

        try:
            cleaned_text = response.text.replace("```json", "").replace("```", "").strip()
            result = json.loads(cleaned_text)
        except (json.JSONDecodeError, AttributeError, ValueError) as e:
            logger.error(f"[USER_ID: {user_id}] - Failed to decode Gemini response: {e}", exc_info=True)
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–∏—Å–∞ –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")
            return ConversationHandler.END

        page_number = result.get("page", 0)
        if page_number == 0:
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—É. –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –≤—Ä—É—á–Ω—É—é.")
            return AWAITING_MANUAL_PAGE

        context.user_data["found_page_number"] = page_number
        pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
        page = pdf_document.load_page(page_number - 1)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è Telegram
        img_buffer = prepare_telegram_image(page, user_id)
        pdf_document.close()

        keyboard = [[InlineKeyboardButton("‚úÖ –î–∞", callback_data="yes"), InlineKeyboardButton("‚ùå –ù–µ—Ç", callback_data="no")]]
        
        try:
            await update.message.reply_photo(
                photo=img_buffer,
                caption=f"–≠—Ç–æ –≤–µ—Ä–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number})?",
                reply_markup=InlineKeyboardMarkup(keyboard),
            )
        except telegram.error.BadRequest as e:
            if "Photo_invalid_dimensions" in str(e):
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                logger.warning(f"[USER_ID: {user_id}] - Failed to send photo, sending text message instead: {e}")
                await update.message.reply_text(
                    f"–ù–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number}. –≠—Ç–æ –≤–µ—Ä–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞?",
                    reply_markup=InlineKeyboardMarkup(keyboard)
                )
            else:
                raise e
                
        return AWAITING_CONFIRMATION

    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error in handle_document: {e}", exc_info=True)
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.")
        return ConversationHandler.END
    finally:
        if temp_pdf_path and os.path.exists(temp_pdf_path):
            os.remove(temp_pdf_path)

async def handle_confirmation_choice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    if query.data == "yes":
        # –ü—Ä–æ–±—É–µ–º –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å caption, –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        processing_message = """üéØ –û—Ç–ª–∏—á–Ω–æ! –°—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞!

üöÄ –ù–∞—á–∏–Ω–∞—é –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É:
‚Ä¢ üì∑ –ò–∑–≤–ª–µ–∫–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –≤—ã—Å–æ–∫–æ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏
‚Ä¢ üîç –†–∞—Å–ø–æ–∑–Ω–∞—é —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ Azure OCR
‚Ä¢ ü§ñ –ò—Å–ø—Ä–∞–≤–ª—è—é –æ—à–∏–±–∫–∏ —Å –ø–æ–º–æ—â—å—é –ò–ò
‚Ä¢ üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü—ã
‚Ä¢ üìà –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç—á–µ—Ç—ã Excel –∏ TXT

‚è∞ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 1-3 –º–∏–Ω—É—Ç—ã
*–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–∂–∏–¥–∞–π—Ç–µ...*"""

        try:
            await query.edit_message_caption(caption=processing_message)
        except telegram.error.BadRequest as e:
            if "There is no caption in the message to edit" in str(e):
                logger.info(f"No caption to edit, using edit_message_text instead: {e}")
                await query.edit_message_text(text=processing_message)
            else:
                raise e
        
        return await process_specification(update, context)
    else:
        # –ü—Ä–æ–±—É–µ–º –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å caption, –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        try:
            await query.edit_message_caption(caption="–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã:")
        except telegram.error.BadRequest as e:
            if "There is no caption in the message to edit" in str(e):
                logger.info(f"No caption to edit, using edit_message_text instead: {e}")
                await query.edit_message_text(text="–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã:")
            else:
                raise e
        
        return AWAITING_MANUAL_PAGE

async def handle_manual_page_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        page_number = int(update.message.text)
        context.user_data["manual_page_number"] = page_number
        await update.message.reply_text(f"–ü—Ä–∏–Ω—è—Ç–æ. –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}...")
        return await process_specification(update, context)
    except (ValueError):
        await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã.")
        return AWAITING_MANUAL_PAGE

async def handle_file_url(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–∞–π–ª —Å —Ñ–∞–π–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫–∞.
    """
    user_id = update.effective_user.id
    url = update.message.text.strip()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ URL –¥–ª—è Dropbox
    file_name_from_url = "unknown"
    try:
        # –î–ª—è Dropbox —Å—Å—ã–ª–æ–∫ –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ –ø—É—Ç–∏
        import urllib.parse
        parsed_url = urllib.parse.urlparse(url)
        path_parts = parsed_url.path.split('/')
        for part in path_parts:
            if part.endswith('.pdf'):
                file_name_from_url = part
                break
    except:
        file_name_from_url = "dropbox_file.pdf"
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ GCS
    context.user_data["pdf_file_name"] = file_name_from_url
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Å—Å—ã–ª–∫–∏
    if not is_valid_file_url(url):
        supported_services = """‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ Dropbox

üîó –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –Ω–∞ Dropbox:
üëâ https://dropbox.com

üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å—Å—ã–ª–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∞ –¥–ª—è –æ–±—â–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞"""
        await update.message.reply_text(supported_services)
        return AWAITING_URL
    
    await update.message.reply_text("üîÑ –°–∫–∞—á–∏–≤–∞—é —Ñ–∞–π–ª –ø–æ —Å—Å—ã–ª–∫–µ...")
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        pdf_bytes = await download_file_from_url(url, user_id)
        logger.info(f"[USER_ID: {user_id}] - File downloaded from URL: {len(pdf_bytes)} bytes")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ PDF
        try:
            pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
            num_pages = len(pdf_document)
            pdf_document.close()
        except Exception:
            await update.message.reply_text("‚ùå –§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º PDF-–¥–æ–∫—É–º–µ–Ω—Ç–æ–º.")
            return AWAITING_URL
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
        if num_pages > 100:
            await update.message.reply_text(f"‚ùå –î–æ–∫—É–º–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({num_pages} —Å—Ç—Ä–∞–Ω–∏—Ü). –ú–∞–∫—Å–∏–º—É–º 100 —Å—Ç—Ä–∞–Ω–∏—Ü.")
            return AWAITING_URL
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
        context.user_data["pdf_bytes"] = pdf_bytes
        await update.message.reply_text(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω! –î–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç {num_pages} —Å—Ç—Ä–∞–Ω–∏—Ü. –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑...")
        
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∫–∞–∫ –æ–±—ã—á–Ω–æ
        temp_pdf_path = None
        try:
            os.makedirs(TEMP_DIR, exist_ok=True)
            temp_pdf_path = os.path.join(TEMP_DIR, f"{user_id}_check.pdf")
            with open(temp_pdf_path, "wb") as f:
                f.write(pdf_bytes)

            logger.info(f"[USER_ID: {user_id}] - STEP 1: Performing validation and page search with Gemini.")
            gemini_file = genai.upload_file(path=temp_pdf_path)
            prompt = get_prompt("find_and_validate.txt")
            model = create_gemini_model()
            
            response = await run_gemini_with_retry(model, prompt, gemini_file, user_id)
            genai.delete_file(gemini_file.name)

            try:
                cleaned_text = response.text.replace("```json", "").replace("```", "").strip()
                result = json.loads(cleaned_text)
            except (json.JSONDecodeError, AttributeError, ValueError) as e:
                logger.error(f"[USER_ID: {user_id}] - Failed to decode Gemini response: {e}", exc_info=True)
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–∏—Å–∞ –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")
                return ConversationHandler.END

            page_number = result.get("page", 0)
            if page_number == 0:
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—É. –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –≤—Ä—É—á–Ω—É—é.")
                return AWAITING_MANUAL_PAGE

            context.user_data["found_page_number"] = page_number
            pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
            page = pdf_document.load_page(page_number - 1)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è Telegram
            img_buffer = prepare_telegram_image(page, user_id)
            pdf_document.close()

            keyboard = [[InlineKeyboardButton("‚úÖ –î–∞", callback_data="yes"), InlineKeyboardButton("‚ùå –ù–µ—Ç", callback_data="no")]]
            
            try:
                await update.message.reply_photo(
                    photo=img_buffer,
                    caption=f"–≠—Ç–æ –≤–µ—Ä–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number})?",
                    reply_markup=InlineKeyboardMarkup(keyboard),
                )
            except telegram.error.BadRequest as e:
                if "Photo_invalid_dimensions" in str(e):
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                    logger.warning(f"[USER_ID: {user_id}] - Failed to send photo, sending text message instead: {e}")
                    await update.message.reply_text(
                        f"–ù–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number}. –≠—Ç–æ –≤–µ—Ä–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞?",
                        reply_markup=InlineKeyboardMarkup(keyboard)
                    )
                else:
                    raise e
                    
            return AWAITING_CONFIRMATION

        except Exception as e:
            logger.error(f"[USER_ID: {user_id}] - Error in handle_file_url: {e}", exc_info=True)
            await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.")
            return ConversationHandler.END
        finally:
            if temp_pdf_path and os.path.exists(temp_pdf_path):
                os.remove(temp_pdf_path)
        
    except ValueError as e:
        # –û—à–∏–±–∫–∏ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        await update.message.reply_text(f"‚ùå {str(e)}")
        return AWAITING_URL
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error downloading file from URL: {e}", exc_info=True)
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Å—ã–ª–∫—É –∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.")
        return AWAITING_URL

async def handle_feedback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    query = update.callback_query
    await query.answer()
    
    user_id = update.effective_user.id
    processed_files = context.user_data.get("processed_files", {})
    base_path = processed_files.get("base_path")
    
    if not base_path:
        await query.edit_message_text("‚ùå –û—à–∏–±–∫–∞: –¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        context.user_data.clear()
        return ConversationHandler.END
    
    # –û—Ç–º–µ–Ω—è–µ–º timeout –∑–∞–¥–∞—á—É
    if user_id in pending_feedback_tasks:
        pending_feedback_tasks[user_id]["cancel"] = True
        pending_feedback_tasks.pop(user_id, None)
        logger.info(f"[USER_ID: {user_id}] - Feedback timeout cancelled (user responded)")
    
    if query.data == "feedback_yes":
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–≤–æ–ª–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        await query.edit_message_text("‚úÖ –°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É! –í–∞—à –æ—Ç–∑—ã–≤ –ø–æ–º–æ–∂–µ—Ç –Ω–∞–º —É–ª—É—á—à–∞—Ç—å —Å–µ—Ä–≤–∏—Å.")
        
        # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º GCS –∑–∞–ø–∏—Å—å —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é
        await finalize_gcs_entry(base_path, "good")
        
        context.user_data.clear()
        return ConversationHandler.END
        
    elif query.data == "feedback_no":
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ–¥–æ–≤–æ–ª–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º - –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –¥–∏–∞–ª–æ–≥—É —Å –∞–¥–º–∏–Ω–æ–º
        contact_message = """‚ùå –ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ

üîß –ù–∞–ø–∏—à–∏—Ç–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å:
üë§ @aianback

üìù –û–ø–∏—à–∏—Ç–µ –ø—Ä–æ–±–ª–µ–º—É:
‚Ä¢ –ö–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ –æ—à–∏–±–∫–∏ –≤—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏  
‚Ä¢ –ù–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
‚Ä¢ –ß—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ

‚ö° –í–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏!

–°–ø–∞—Å–∏–±–æ –∑–∞ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å! üôè

üí¨ –ù–∞–∂–º–∏—Ç–µ –Ω–∞ @aianback —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å —á–∞—Ç"""
        
        # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ –¥–∏–∞–ª–æ–≥—É —Å –∞–¥–º–∏–Ω–æ–º
        admin_keyboard = [[InlineKeyboardButton("üí¨ –ù–∞–ø–∏—Å–∞—Ç—å –∞–¥–º–∏–Ω—É", url="https://t.me/aianback")]]
        
        await query.edit_message_text(
            contact_message,
            reply_markup=InlineKeyboardMarkup(admin_keyboard)
        )
        
        # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º GCS –∑–∞–ø–∏—Å—å —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é
        await finalize_gcs_entry(base_path, "bad")
        
        context.user_data.clear()
        return ConversationHandler.END

async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–î–µ–π—Å—Ç–≤–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")
    context.user_data.clear()
    return ConversationHandler.END

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—à–∏–±–∫–∏ –±–æ—Ç–∞"""
    logger.error(f"Exception while handling an update: {context.error}", exc_info=context.error)
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å update, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
    if isinstance(update, Update) and update.effective_chat:
        error_message = """üòî –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞!

üîß –ß—Ç–æ –¥–µ–ª–∞—Ç—å:
‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ (—Ç–æ–ª—å–∫–æ PDF)
‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–æ 20 –ú–ë

üí¨ –ù—É–∂–Ω–∞ –ø–æ–º–æ—â—å? –ù–∞–ø–∏—à–∏—Ç–µ /start –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞"""
        
        try:
            await context.bot.send_message(
                chat_id=update.effective_chat.id,
                text=error_message
            )
        except Exception:
            pass

def main():
    if not all([TELEGRAM_BOT_TOKEN, AZURE_ENDPOINT, AZURE_KEY, GEMINI_API_KEY]):
        logger.critical("FATAL: One or more environment variables are missing!")
        return
    
    if not GCS_BUCKET:
        logger.warning("GCS_BUCKET not configured - archiving will be disabled")

    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ webhook'–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
    try:
        import requests
        response = requests.post(f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/deleteWebhook")
        logger.info("Webhook deleted to prevent conflicts")
    except Exception as e:
        logger.warning(f"Could not delete webhook: {e}")

    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
    app.add_error_handler(error_handler)
    
    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("start", start)],
        states={
            SELECTING_ACTION: [
                MessageHandler(filters.Document.PDF, handle_document),
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_file_url)
            ],
            AWAITING_CONFIRMATION: [CallbackQueryHandler(handle_confirmation_choice)],
            AWAITING_MANUAL_PAGE: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_manual_page_input)],
            AWAITING_URL: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_file_url)],
            AWAITING_FEEDBACK: [CallbackQueryHandler(handle_feedback)],
        },
        fallbacks=[CommandHandler("cancel", cancel)],
        per_message=False,  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã –∫–æ–º–∞–Ω–¥
    )
    app.add_handler(conv_handler)
    
    logger.info("ü§ñ === BOT INITIALIZED SUCCESSFULLY ===")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã (webhook –∏–ª–∏ polling)
    webhook_url = os.getenv("WEBHOOK_URL")
    port = int(os.getenv("PORT", "8080"))
    
    if webhook_url:
        logger.info("üåê Starting in WEBHOOK mode...")
        logger.info(f"üîó Webhook URL: {webhook_url}")
        logger.info(f"üö™ Port: {port}")
        
        try:
            app.run_webhook(
                listen="0.0.0.0",
                port=port,
                webhook_url=webhook_url,
                drop_pending_updates=True,
                allowed_updates=Update.ALL_TYPES
            )
        except Exception as e:
            logger.critical(f"Failed to start webhook: {e}")
            raise
    else:
        logger.info("üìû Starting in POLLING mode...")
        
        try:
            app.run_polling(drop_pending_updates=True, allowed_updates=Update.ALL_TYPES)
        except Exception as e:
            logger.critical(f"Failed to start polling: {e}")
            raise

if __name__ == "__main__":
    main()