import os
import logging
import io
import json
import base64
import tempfile
import re
import gzip
import uuid
from datetime import datetime, timezone
from PIL import Image
import fitz  # PyMuPDF
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
import google.generativeai as genai
import asyncio
import random
import httpx
import telegram
from dotenv import load_dotenv
from typing import Dict, Optional
import threading
import time
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ConversationHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)
from azure.core.credentials import AzureKeyCredential
from azure.ai.documentintelligence.aio import DocumentIntelligenceClient
from azure.ai.documentintelligence.models import AnalyzeResult, DocumentTable
from google.generativeai.types import GenerationConfig, HarmCategory, HarmBlockThreshold
from yandex_storage import yandex_storage

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
# –ó–∞–≥—Ä—É–∂–∞–µ–º .env.local –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –æ–±—ã—á–Ω—ã–π .env
if os.path.exists('.env.local'):
    load_dotenv('.env.local')
    print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω .env.local (–ª–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞)")
else:
    load_dotenv()
    print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω .env (—Å–µ—Ä–≤–µ—Ä)")

# –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Yandex Storage –∫–ª–∏–µ–Ω—Ç,
# —á—Ç–æ–±—ã —É—á–µ—Å—Ç—å —Å–≤–µ–∂–∏–µ –∫–ª—é—á–∏/–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–∏–Ω–∞—á–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–ªc—è —Ä–∞–Ω—å—à–µ —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏).
try:
    from yandex_storage import reinitialize_global_client as _reinit_ys
    _reinit_ys()
except Exception as _e:
    logger.warning(f"Could not reinitialize Yandex Storage client: {_e}")

# API –ö–ª—é—á–∏
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL_NAME = os.getenv("GEMINI_MODEL_NAME", "gemini-1.5-pro-latest") # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ
AZURE_ENDPOINT = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT")
AZURE_KEY = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

PROMPT_VERSION = os.getenv("PROMPT_VERSION", "v1.0")

# Vertex AI (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ). –ï—Å–ª–∏ –∑–∞–¥–∞–Ω–æ USE_VERTEX_AI=1, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—Ä–µ–¥–∏—Ç—ã Vertex.
USE_VERTEX_AI = os.getenv("USE_VERTEX_AI", "0") == "1"
VERTEX_PROJECT_ID = os.getenv("VERTEX_PROJECT_ID")
VERTEX_LOCATION = os.getenv("VERTEX_LOCATION", "us-central1")

# –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–æ–π –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏ (GCS). –°–µ–π—á–∞—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Yandex Storage,
# –Ω–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ—Å—Ç–∞–ª–∞—Å—å –Ω–∏–∂–µ. –û–±—ä—è–≤–ª—è–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å NameError.
GCS_BUCKET = os.getenv("GCS_BUCKET")

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - [%(levelname)s] - (%(name)s) - %(message)s",
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º –ø—Ä—è–º–æ–π Gemini API –∫–ª—é—á, –µ—Å–ª–∏ –æ–Ω –∑–∞–¥–∞–Ω –∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Vertex AI
try:
    if GEMINI_API_KEY and os.getenv("USE_VERTEX_AI", "0") != "1":
        genai.configure(api_key=GEMINI_API_KEY)
        logger.info("Gemini API configured with direct API key")
    else:
        logger.info("Skipping direct Gemini API config (using Vertex or no key provided)")
except Exception as _e:
    logger.warning(f"Failed to configure Gemini API key: {_e}")

# –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Railway: GCS credentials –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
if os.getenv("GOOGLE_APPLICATION_CREDENTIALS_JSON"):
    import tempfile
    import json
    try:
        credentials_json = os.getenv("GOOGLE_APPLICATION_CREDENTIALS_JSON")
        credentials = json.loads(credentials_json)
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f:
            json.dump(credentials, f)
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = f.name
        logger.info("‚úÖ GCS credentials loaded from environment variable")
    except Exception as e:
        logger.error(f"‚ùå Failed to load GCS credentials from environment: {e}")

# –û—Ç–∫–ª—é—á–∞–µ–º —Å–ø–∞–º HTTP –∑–∞–ø—Ä–æ—Å–æ–≤
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("telegram.ext._updater").setLevel(logging.WARNING)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
(SELECTING_ACTION, AWAITING_CONFIRMATION, AWAITING_MANUAL_PAGE, AWAITING_URL, AWAITING_FEEDBACK) = range(5)
TEMP_DIR = "temp_bot_files"
MAX_RETRIES = 3
GEMINI_TIMEOUT_SECONDS = 120  # 2 –º–∏–Ω—É—Ç—ã —Ç–∞–π–º–∞—É—Ç –¥–ª—è Gemini API
FEEDBACK_TIMEOUT_SECONDS = 1800  # 30 –º–∏–Ω—É—Ç –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
pending_feedback_tasks: Dict[int, Dict] = {}

# --- –§—É–Ω–∫—Ü–∏–∏-–ø–æ–º–æ—â–Ω–∏–∫–∏ ---

def create_gemini_model(model_name: str = None):
    """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å Gemini. –ü—Ä–∏ USE_VERTEX_AI=1 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Vertex AI SDK.

    –ü—Ä–æ–º–ø—Ç—ã –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–µ –º–µ–Ω—è—é—Ç—Å—è.
    """
    if model_name is None:
        model_name = GEMINI_MODEL_NAME

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º)
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

    if USE_VERTEX_AI:
        try:
            import vertexai
            from vertexai.generative_models import GenerativeModel as VGenerativeModel

            if not VERTEX_PROJECT_ID:
                logger.critical("USE_VERTEX_AI=1, –Ω–æ –Ω–µ –∑–∞–¥–∞–Ω VERTEX_PROJECT_ID")
            vertexai.init(project=VERTEX_PROJECT_ID, location=VERTEX_LOCATION)

            v_model = VGenerativeModel(model_name)

            class VertexModelWrapper:
                def __init__(self, inner, name):
                    self._inner = inner
                    # –î–ª—è –ª–æ–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç, –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π Google SDK
                    self.model_name = f"models/{name}"

                async def generate_content_async(self, parts, generation_config=None):
                    # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ Vertex –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ –ø–æ—Ç–æ–∫
                    def call():
                        # –ü—ã—Ç–∞–µ–º—Å—è –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –ø—Ä–æ–±—Ä–æ—Å–∏—Ç—å generation_config, –µ—Å–ª–∏ –æ–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –ø–æ–ª—è
                        try:
                            # Vertex —Ç–∞–∫–∂–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç response_mime_type, max_output_tokens –∏ –¥—Ä.
                            if generation_config is not None:
                                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Google AI GenerationConfig –≤ Vertex AI —Ñ–æ—Ä–º–∞—Ç
                                if hasattr(generation_config, 'response_mime_type'):
                                    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è Vertex AI
                                    vertex_config = {}
                                    if generation_config.response_mime_type:
                                        vertex_config['response_mime_type'] = generation_config.response_mime_type
                                    if hasattr(generation_config, 'max_output_tokens') and generation_config.max_output_tokens:
                                        vertex_config['max_output_tokens'] = generation_config.max_output_tokens
                                    if hasattr(generation_config, 'temperature') and generation_config.temperature is not None:
                                        vertex_config['temperature'] = generation_config.temperature
                                    
                                    return self._inner.generate_content(parts, generation_config=vertex_config)
                                else:
                                    # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ —Å–ª–æ–≤–∞—Ä—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
                                    return self._inner.generate_content(parts, generation_config=generation_config)
                            return self._inner.generate_content(parts)
                        except (TypeError, AttributeError):
                            # –ï—Å–ª–∏ —Ç–∏–ø –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ —Å–æ–≤–ø–∞–ª ‚Äî –≤—ã–∑—ã–≤–∞–µ–º –±–µ–∑ –Ω–µ–µ
                            return self._inner.generate_content(parts)

                    return await asyncio.to_thread(call)

            return VertexModelWrapper(v_model, model_name)
        except Exception as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Vertex AI SDK: {e}")
            # –§–æ–ª–±—ç–∫ –Ω–∞ –ø—Ä—è–º–æ–π Gemini API (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–ª—é—á)

    # –û–±—ã—á–Ω—ã–π Gemini API
    return genai.GenerativeModel(
        model_name=model_name,
        safety_settings=safety_settings
    )

async def wait_for_gemini_file_active(gemini_file, user_id: int, timeout_seconds: int = 180, poll_interval: float = 1.5):
    """–û–∂–∏–¥–∞–µ—Ç, –ø–æ–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª Gemini –ø–µ—Ä–µ–π–¥–µ—Ç –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ ACTIVE.

    –ë–µ–∑ —ç—Ç–æ–π –ø–∞—É–∑—ã –≤—ã–∑–æ–≤ generate_content –º–æ–∂–µ—Ç –ø–∞–¥–∞—Ç—å 500, –ø–æ–∫–∞ —Ñ–∞–π–ª –µ—â–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è.
    """
    start_ts = time.time()
    last_state = None
    try:
        while True:
            f = genai.get_file(gemini_file.name)
            state = getattr(f, "state", None)
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ state: str, enum, int
            state_name = None
            if hasattr(state, "name"):
                state_name = state.name
            elif isinstance(state, str):
                state_name = state
            
            # –ü–æ–¥—Ä–æ–±–Ω—ã–π –ª–æ–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            if state != last_state:
                logger.info(f"[USER_ID: {user_id}] - Gemini file state: {state} (type={type(state).__name__}, name={state_name})")
                last_state = state

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º ACTIVE/FAILED –ø–æ —Å—Ç—Ä–æ–∫–µ –∏–º–µ–Ω–∏
            if state_name:
                up = str(state_name).upper()
                if "ACTIVE" in up:
                    return f
                if "FAILED" in up:
                    raise RuntimeError("Gemini file processing failed")

            # –ï—Å–ª–∏ –ø—Ä–∏—à–ª–æ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ‚Äî –º–∞–ø–ø–∏–º –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π —Å—Ö–µ–º–µ: 0=UNSPECIFIED,1=PROCESSING,2=ACTIVE,3=FAILED
            if isinstance(state, int):
                if state == 2:
                    return f
                if state == 3:
                    raise RuntimeError("Gemini file processing failed")
                # 0/1 ‚Äî –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤
            if time.time() - start_ts > timeout_seconds:
                raise TimeoutError("Timed out waiting for Gemini file to become ACTIVE")
            await asyncio.sleep(poll_interval)
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error while waiting for Gemini file ACTIVE: {e}")
        raise

def get_prompt(file_path: str) -> str:
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        logger.error(f"Prompt file not found: {file_path}")
        return ""

def create_ocr_correction_prompt(ocr_text: str) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ OCR –æ—à–∏–±–æ–∫, –∏—Å–ø–æ–ª—å–∑—É—è –ª–æ–≥–∏–∫—É –∏–∑ 2b_ocr_correction.py.
    """
    prompt = f"""
üîß –ó–ê–î–ê–ß–ê: –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –æ—à–∏–±–æ–∫ OCR –≤ —Ç–∞–±–ª–∏—Ü–µ –º–µ—Ç–∞–ª–ª–æ–ø—Ä–æ–∫–∞—Ç–∞

üìã –ò–°–•–û–î–ù–´–ô –¢–ï–ö–°–¢ OCR:
{ocr_text}

üéØ –¶–ï–õ–¨: –ò—Å–ø—Ä–∞–≤–∏—Ç—å —Ç–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ OCR —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã

‚ö° –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:

1. **–†–ê–ó–ú–ï–†–´ –ü–†–û–§–ò–õ–ï–ô:**
   - 20–ë1, 20–ëI, 20BI ‚Üí 20–®1 (–¥–≤—É—Ç–∞–≤—Ä —à–∏—Ä–æ–∫–æ–ø–æ–ª–æ—á–Ω—ã–π)
   - [16n, [16–ø ‚Üí 16–ø (—à–≤–µ–ª–ª–µ—Ä)  
   - [200, [120 ‚Üí 200, 120 (—à–≤–µ–ª–ª–µ—Ä)
   - C247 ‚Üí 24–£ (—à–≤–µ–ª–ª–µ—Ä —Å —É–∫–ª–æ–Ω–æ–º)
   - +5, s5 ‚Üí s5 (–ª–∏—Å—Ç —Ç–æ–ª—â–∏–Ω–æ–π 5–º–º)
   - nucm ‚Üí –ª–∏—Å—Ç (–ø—Ä–æ—Å–µ—á–Ω–æ-–≤—ã—Ç—è–∂–Ω–æ–π)
   
2. **–ú–ê–†–ö–ò –°–¢–ê–õ–ò:**
   - –°5, –°—Ç5 ‚Üí –°—Ç3 (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ OCR –æ—à–∏–±–∫–∏)
   - –°6 ‚Üí –°235 (–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç)
   - C255, C245, C275 ‚Üí –°255, –°245, –°275 (–ª–∞—Ç–∏–Ω—Å–∫–∞—è C ‚Üí –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∞—è –°)
   
3. **–ù–ê–ó–í–ê–ù–ò–Ø –ü–†–û–§–ò–õ–ï–ô:**
   - –î–≤—É—Ç–∞–≤—Ä—ã ‚Üí –î–≤—É—Ç–∞–≤—Ä—ã —Å—Ç–∞–ª—å–Ω—ã–µ –≥–æ—Ä—è—á–µ–∫–∞—Ç–∞–Ω–Ω—ã–µ
   - –®–≤–µ–ª–ª–µ—Ä—ã ‚Üí –®–≤–µ–ª–ª–µ—Ä—ã —Å—Ç–∞–ª—å–Ω—ã–µ –≥–æ—Ä—è—á–µ–∫–∞—Ç–∞–Ω–Ω—ã–µ
   - –£–≥–æ–ª–∫–∏ ‚Üí –£–≥–æ–ª–∫–∏ —Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∞–≤–Ω–æ–ø–æ–ª–æ—á–Ω—ã–µ
   - –õ–∏—Å—Ç—ã ‚Üí –õ–∏—Å—Ç—ã —Å—Ç–∞–ª—å–Ω—ã–µ –≥–æ—Ä—è—á–µ–∫–∞—Ç–∞–Ω–Ω—ã–µ

4. **–ú–ê–°–°–´ –ò –ö–û–õ–ò–ß–ï–°–¢–í–ê:**
   - –ò—Å–ø—Ä–∞–≤—å –æ—á–µ–≤–∏–¥–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ —á–∏—Å–ª–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1O ‚Üí 10)
   - –°–æ—Ö—Ä–∞–Ω–∏ –¥–µ—Å—è—Ç–∏—á–Ω—ã–µ –¥—Ä–æ–±–∏ –∫–∞–∫ –µ—Å—Ç—å
   
üö® –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
- –û—à–∏–±–∫–∏ OCR —á–∞—â–µ –≤ –ë–£–ö–í–ê–•, —Ü–∏—Ñ—Ä—ã –≤ 99% —Å–ª—É—á–∞–µ–≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ
- –°–æ—Ö—Ä–∞–Ω–∏ –í–°–Æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã (—Å—Ç—Ä–æ–∫–∏, —Å—Ç–æ–ª–±—Ü—ã, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
- –ù–ï –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —Ç–æ–ª—å–∫–æ –∏—Å–ø—Ä–∞–≤–ª—è–π –æ—à–∏–±–∫–∏
- –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü –∫–∞–∫ –µ—Å—Ç—å
- –ò—Å–ø—Ä–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ –û–ß–ï–í–ò–î–ù–´–ï –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

üìã –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã –¥–æ–ª–∂–Ω–∞ –æ—Å—Ç–∞—Ç—å—Å—è –∏–¥–µ–Ω—Ç–∏—á–Ω–æ–π –∏—Å—Ö–æ–¥–Ω–æ–π.

üîç –ù–ê–ß–ò–ù–ê–ô –ö–û–†–†–ï–ö–¶–ò–Æ:
"""
    return prompt

def table_to_html(table: DocumentTable) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ–±—ä–µ–∫—Ç —Ç–∞–±–ª–∏—Ü—ã –∏–∑ Azure –≤ HTML-—Å—Ç—Ä–æ–∫—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–æ—Å—Ç—É—é —Å–µ—Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É."""
    if not table.cells:
        return ""
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ—Ç–∫—É —Ç–∞–±–ª–∏—Ü—ã
    grid = [['' for _ in range(table.column_count)] for _ in range(table.row_count)]
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º —Å–µ—Ç–∫—É —Å–æ–¥–µ—Ä–∂–∏–º—ã–º —è—á–µ–µ–∫
    for cell in table.cells:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–Ω–¥–µ–∫—Å—ã –Ω–µ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ –ø—Ä–µ–¥–µ–ª—ã —Å–µ—Ç–∫–∏
        if cell.row_index < table.row_count and cell.column_index < table.column_count:
            grid[cell.row_index][cell.column_index] = cell.content or ''

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML
    html_parts = ['<table border="1">']
    for row in grid:
        html_parts.append('<tr>')
        for cell_content in row:
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º HTML-—Å—É—â–Ω–æ—Å—Ç–∏
            import html
            html_parts.append(f'<td>{html.escape(cell_content)}</td>')
        html_parts.append('</tr>')
    html_parts.append('</table>')
    
    return '\n'.join(html_parts)

def flatten_json_to_dataframe(data: dict) -> pd.DataFrame:
    flat_list = []
    unit = data.get("–µ–¥–∏–Ω–∏—Ü–∞_–∏–∑–º–µ—Ä–µ–Ω–∏—è", "–Ω–µ —É–∫–∞–∑–∞–Ω–∞")
    for profile, p_data in data.get("–ø—Ä–æ—Ñ–∏–ª–∏", {}).items():
        for steel, s_data in p_data.get("–º–∞—Ä–∫–∏_—Å—Ç–∞–ª–∏", {}).items():
            for size, z_data in s_data.get("—Ä–∞–∑–º–µ—Ä—ã", {}).items():
                # –ò–∑–º–µ–Ω–µ–Ω–æ: —Ç–µ–ø–µ—Ä—å –ø–µ—Ä–µ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫, –∞ –Ω–µ —Å–ª–æ–≤–∞—Ä—å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
                for e_data in z_data.get("—ç–ª–µ–º–µ–Ω—Ç—ã", []):
                    flat_list.append({
                        "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è": profile,
                        "–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏": steel,
                        "–†–∞–∑–º–µ—Ä –ø—Ä–æ—Ñ–∏–ª—è": size,
                        "–¢–∏–ø —ç–ª–µ–º–µ–Ω—Ç–∞": e_data.get("—Ç–∏–ø"), # –î–∞–Ω–Ω—ã–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è –≤ —Å–ø–∏—Å–∫–µ
                        "–ü–æ–∑–∏—Ü–∏–∏": ", ".join(map(str, e_data.get("–ø–æ–∑–∏—Ü–∏–∏", []))),
                        f"–ú–∞—Å—Å–∞, {unit}": e_data.get("–º–∞—Å—Å–∞"),
                    })
    return pd.DataFrame(flat_list)

async def run_gemini_with_fallback(html_content: str, user_id: int, chat) -> dict:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç Gemini —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –ø—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞—Ö"""
    logger.info(f"[USER_ID: {user_id}] - Starting Gemini processing with fallback strategy")
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
    try:
        logger.info(f"[USER_ID: {user_id}] - Fallback Strategy 1: Full content with disabled safety")
        prompt = get_prompt("extract_and_correct.txt")
        model = create_gemini_model()
        
        response = await run_gemini_with_retry(
            model, 
            prompt, 
            html_content, 
            user_id, 
            generation_config=GenerationConfig(response_mime_type="application/json")
        )
        
        json_data = parse_gemini_json(response, user_id, debug_tag="s1_full")
        logger.info(f"[USER_ID: {user_id}] - ‚úÖ Strategy 1 successful!")
        return json_data
        
    except Exception as e1:
        logger.warning(f"[USER_ID: {user_id}] - Strategy 1 failed: {e1}")
        # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ–∂–µ—Ç –≤—Ö–æ–¥—è—â–∏–π —Ñ–∞–π–ª; —É–≤–µ–¥–æ–º–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        try:
            await chat.send_message("‚ö†Ô∏è –í–æ–∑–Ω–∏–∫–ª–∏ –Ω–µ–ø–æ–ª–∞–¥–∫–∏, –Ω–∞–ø–∏—à–∏—Ç–µ –∞–¥–º–∏–Ω—É.")
        except Exception:
            pass
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –±–µ–∑ HTML —Ç–µ–≥–æ–≤
        try:
                await chat.send_message("üîß **–ü—Ä–∏–º–µ–Ω—è—é —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥...**\n\nüìÑ **–ò–∑–≤–ª–µ–∫–∞—é —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ**\n*–ë–µ–∑ HTML —Ä–∞–∑–º–µ—Ç–∫–∏*")
                
                logger.info(f"[USER_ID: {user_id}] - Fallback Strategy 3: Plain text only")
                
                # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
                import re
                plain_text = re.sub(r'<[^>]+>', ' ', html_content)
                plain_text = re.sub(r'\s+', ' ', plain_text).strip()
                
                # –£–∫–æ—Ä–æ—á–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                simple_prompt = f"""–ò–∑–≤–ª–µ–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–µ—Ç–∞–ª–ª–æ–ø—Ä–æ–∫–∞—Ç–∞ –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:

–¢–ï–ö–°–¢:
{plain_text[:3000]}...

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (JSON):
{{
  "–µ–¥–∏–Ω–∏—Ü–∞_–∏–∑–º–µ—Ä–µ–Ω–∏—è": "—Ç",
  "–ø—Ä–æ—Ñ–∏–ª–∏": {{
    "–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è": {{
      "–º–∞—Ä–∫–∏_—Å—Ç–∞–ª–∏": {{
        "–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏": {{
          "—Ä–∞–∑–º–µ—Ä—ã": {{
            "–†–∞–∑–º–µ—Ä": {{
              "—ç–ª–µ–º–µ–Ω—Ç—ã": [
                {{"—Ç–∏–ø": "–æ–ø–∏—Å–∞–Ω–∏–µ", "–ø–æ–∑–∏—Ü–∏–∏": ["1"], "–º–∞—Å—Å–∞": 0.0}}
              ]
            }}
          }}
        }}
      }}
    }}
  }}
}}

–ò–∑–≤–ª–µ–∫–∏ –º–∞–∫—Å–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""

                response = await run_gemini_with_retry(
                    model, 
                    simple_prompt, 
                    "", 
                    user_id, 
                    generation_config=GenerationConfig(response_mime_type="application/json")
                )
                
                json_data = parse_gemini_json(response, user_id, debug_tag="s3_plain")
                logger.info(f"[USER_ID: {user_id}] - ‚úÖ Strategy 3 successful!")
                
                await chat.send_message("‚úÖ **–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!**\n*–ò–∑–≤–ª–µ—á–µ–Ω—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ*")
                return json_data
                
        except Exception as e3:
            logger.error(f"[USER_ID: {user_id}] - All fallback strategies failed: {e3}")
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 4: –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ OCR
            await chat.send_message("üîÑ **–°–æ–∑–¥–∞—é –æ—Ç—á–µ—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ OCR**\n\nüìÑ **–í –æ—Ç—á–µ—Ç–µ –±—É–¥—É—Ç:**\n‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ Azure OCR\n‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ä—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏\n‚Ä¢ –í—Å–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ HTML –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            import re
            plain_text = re.sub(r'<[^>]+>', '\n', html_content)
            lines = [line.strip() for line in plain_text.split('\n') if line.strip()]
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ö–æ—Ç—è –±—ã —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            numbers = re.findall(r'\d+[,.]?\d*', plain_text)
            
            fallback_data = {
                "–µ–¥–∏–Ω–∏—Ü–∞_–∏–∑–º–µ—Ä–µ–Ω–∏—è": "—Ç",
                "–ø—Ä–æ—Ñ–∏–ª–∏": {
                    "–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ OCR": {
                        "–º–∞—Ä–∫–∏_—Å—Ç–∞–ª–∏": {
                            "–¢—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏": {
                                "—Ä–∞–∑–º–µ—Ä—ã": {
                                    "–í—Å–µ —Ä–∞–∑–º–µ—Ä—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞": {
                                        "—ç–ª–µ–º–µ–Ω—Ç—ã": [{
                                            "—Ç–∏–ø": f"OCR –¥–∞–Ω–Ω—ã–µ ({len(lines)} —Å—Ç—Ä–æ–∫, {len(numbers)} —á–∏—Å–µ–ª)",
                                            "–ø–æ–∑–∏—Ü–∏–∏": ["–í–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç"],
                                            "–º–∞—Å—Å–∞": sum([float(n.replace(',', '.')) for n in numbers[:10] if n.replace(',', '.').replace('.', '').isdigit()]) if numbers else 0.0
                                        }]
                                    }
                                }
                            }
                        }
                    }
                }
            }
            
            logger.info(f"[USER_ID: {user_id}] - ‚úÖ Using fallback minimal data structure")
            return fallback_data

async def run_gemini_with_retry(model, prompt, content, user_id, generation_config=None):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç Gemini —Å retry –ª–æ–≥–∏–∫–æ–π. content –º–æ–∂–µ—Ç –±—ã—Ç—å —Ñ–∞–π–ª–æ–º –∏–ª–∏ —Ç–µ–∫—Å—Ç–æ–º"""
    retries = 0
    last_exception = None
    
    logger.info(f"[USER_ID: {user_id}] - Starting Gemini API call")
    
    while retries < MAX_RETRIES:
        try:
            logger.info(f"[USER_ID: {user_id}] - Gemini API call attempt {retries + 1}/{MAX_RETRIES}")
            
            if generation_config:
                response = await asyncio.wait_for(
                    model.generate_content_async([prompt, content], generation_config=generation_config),
                    timeout=GEMINI_TIMEOUT_SECONDS
                )
            else:
                response = await asyncio.wait_for(
                    model.generate_content_async([prompt, content]),
                    timeout=GEMINI_TIMEOUT_SECONDS
                )
            
            logger.info(f"[USER_ID: {user_id}] - ‚úÖ Gemini API call successful")
            return response
            
        except Exception as e:
            last_exception = e
            logger.error(f"[USER_ID: {user_id}] - ‚ùå Gemini API call failed: {str(e)}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
            if ("500" in str(e) or "internal error" in str(e).lower() or 
                isinstance(e, asyncio.TimeoutError)) and retries < MAX_RETRIES - 1:
                retries += 1
                wait_time = 5 * (2 ** (retries - 1))
                logger.warning(f"[USER_ID: {user_id}] - üîÑ Retrying in {wait_time}s... (attempt {retries + 1}/{MAX_RETRIES})")
                await asyncio.sleep(wait_time)
            else:
                logger.error(f"[USER_ID: {user_id}] - üö´ Non-retryable error or max retries reached")
                raise e
    
    logger.error(f"[USER_ID: {user_id}] - üí• All {MAX_RETRIES} retry attempts failed")
    raise last_exception

async def send_periodic_status_updates(update, user_id, operation_name):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –≤–æ –≤—Ä–µ–º—è –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π"""
    try:
        await asyncio.sleep(60)  # –ü–µ—Ä–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É
        await update.message.reply_text(f"‚è≥ {operation_name.capitalize()} –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ –µ—â–µ –Ω–µ–º–Ω–æ–≥–æ.")
        
        await asyncio.sleep(60)  # –í—Ç–æ—Ä–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 2 –º–∏–Ω—É—Ç—ã
        await update.message.reply_text(f"üîÑ {operation_name.capitalize()} –≤—Å–µ –µ—â–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è... –ë–æ–ª—å—à–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Ç—Ä–µ–±—É—é—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏.")
        
        # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞, –∑–Ω–∞—á–∏—Ç –æ–ø–µ—Ä–∞—Ü–∏—è –¥–ª–∏—Ç—Å—è –±–æ–ª–µ–µ 2 –º–∏–Ω—É—Ç - —ç—Ç–æ —É–∂–µ –¥–æ–ª–≥–æ
        while True:
            await asyncio.sleep(30)  # –î–∞–ª—å—à–µ –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
            await update.message.reply_text(f"‚åõ {operation_name.capitalize()} –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ...")
    except asyncio.CancelledError:
        # –ó–∞–¥–∞—á–∞ –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞, –æ–ø–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å
        pass
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error in status updates: {e}")

def _extract_text_from_gemini_response(response) -> str:
    """Best-effort text extraction from Google/Vertex Gemini response object."""
    try:
        # Prefer unified .text if present
        text = getattr(response, "text", None)
        if isinstance(text, str) and text.strip():
            return text
    except Exception:
        pass

    # Fallback: concatenate parts' text
    parts_text = []
    try:
        candidates = getattr(response, "candidates", None) or []
        for cand in candidates:
            content = getattr(cand, "content", None)
            parts = getattr(content, "parts", None) or []
            for part in parts:
                # Try part.text first (most common)
                pt = getattr(part, "text", None)
                if isinstance(pt, str) and pt:
                    parts_text.append(pt)
                    continue
                # Try inline data (Vertex JSON may come as inline_data)
                inline = getattr(part, "inline_data", None)
                if inline is not None:
                    data = getattr(inline, "data", None)
                    if data:
                        try:
                            # data may already be bytes or base64 string
                            if isinstance(data, (bytes, bytearray)):
                                parts_text.append(data.decode("utf-8", errors="ignore"))
                            elif isinstance(data, str):
                                import base64 as _b64
                                parts_text.append(_b64.b64decode(data).decode("utf-8", errors="ignore"))
                        except Exception:
                            # ignore decoding failures
                            pass
    except Exception:
        pass
    return "".join(parts_text).strip()

def _strip_code_fences(s: str) -> str:
    # Remove ```json ... ``` or ``` ... ``` wrappers
    s = s.strip()
    if s.startswith("```"):
        # drop opening fence with optional language
        s = re.sub(r"^```[a-zA-Z0-9_+-]*\s*", "", s)
        # drop trailing fence
        s = re.sub(r"\n?```\s*$", "", s)
    return s.strip()

def _relaxed_json_parse(raw: str) -> dict:
    """Parse JSON allowing common LLM wrappers. Raises JSONDecodeError on failure."""
    s = _strip_code_fences(raw)
    # Quick try
    try:
        return json.loads(s)
    except Exception:
        pass

    # Try to extract the largest JSON object/array from the text
    # 1) Object {...}
    first_brace = s.find("{")
    last_brace = s.rfind("}")
    if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
        candidate = s[first_brace:last_brace + 1]
        try:
            return json.loads(candidate)
        except Exception:
            # Try to balance braces by scanning
            stack = []
            start = None
            for i, ch in enumerate(s):
                if ch == '{':
                    stack.append('{')
                    if start is None:
                        start = i
                elif ch == '}':
                    if stack:
                        stack.pop()
                        if not stack and start is not None:
                            try:
                                return json.loads(s[start:i+1])
                            except Exception:
                                start = None
            # fallthrough
            pass

    # 2) Array [...]
    first_sq = s.find("[")
    last_sq = s.rfind("]")
    if first_sq != -1 and last_sq != -1 and last_sq > first_sq:
        candidate = s[first_sq:last_sq + 1]
        return json.loads(candidate)

    # If still not parsed, raise the original error
    return json.loads(s)

def parse_gemini_json(response, user_id: int, debug_tag: str = "") -> dict:
    """Unified JSON parsing with diagnostics and relaxed extraction."""
    raw = _extract_text_from_gemini_response(response)
    if not raw:
        raise ValueError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ (–Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞)")
    
    # –í–°–ï–ì–î–ê –ª–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç Gemini
    logger.info(f"[USER_ID: {user_id}] - RAW Gemini response ({debug_tag}): {raw[:500]}{'...' if len(raw) > 500 else ''}")
    
    try:
        result = _relaxed_json_parse(raw)
        logger.info(f"[USER_ID: {user_id}] - Parsed JSON result ({debug_tag}): {result}")
        return result
    except Exception as e:
        # Dump raw to debug file for inspection
        os.makedirs(TEMP_DIR, exist_ok=True)
        ts = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
        suffix = f"_{debug_tag}" if debug_tag else ""
        path = os.path.join(TEMP_DIR, f"gemini_raw_response_{user_id}{suffix}_{ts}.txt")
        try:
            with open(path, "w", encoding="utf-8") as f:
                f.write(raw)
            logger.warning(f"[USER_ID: {user_id}] - Saved raw Gemini response to {path}")
        except Exception as _:
            pass
        raise

def convert_file_sharing_url(url: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Å—ã–ª–∫–∏ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫–æ–≤ –≤ –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.
    """
    # Google Drive
    if "drive.google.com" in url:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID —Ñ–∞–π–ª–∞ –∏–∑ —Å—Å—ã–ª–∫–∏
        match = re.search(r'/d/([a-zA-Z0-9-_]+)', url)
        if match:
            file_id = match.group(1)
            return f"https://drive.google.com/uc?export=download&id={file_id}"
    
    # –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫
    elif "disk.yandex" in url:
        # –î–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞ –Ω—É–∂–µ–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π API-–∑–∞–ø—Ä–æ—Å
        return url  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
    
    # Dropbox
    elif "dropbox.com" in url:
        # –ó–∞–º–µ–Ω—è–µ–º dl=0 –Ω–∞ dl=1 –¥–ª—è –ø—Ä—è–º–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        return url.replace("dl=0", "dl=1").replace("?dl=0", "?dl=1")
    
    # WeTransfer –∏ –¥—Ä—É–≥–∏–µ
    return url

async def download_file_from_url(url: str, user_id: int) -> bytes:
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –ø–æ —Å—Å—ã–ª–∫–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫–æ–≤.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Å—ã–ª–∫—É –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
    download_url = convert_file_sharing_url(url)
    
    async with httpx.AsyncClient(timeout=300.0, follow_redirects=True) as client:
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        try:
            head_response = await client.head(download_url, headers=headers)
            content_length = head_response.headers.get('content-length')
            if content_length and int(content_length) > 50 * 1024 * 1024:  # 50 MB –ª–∏–º–∏—Ç
                raise ValueError(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({int(content_length) / 1024 / 1024:.1f} –ú–ë). –ú–∞–∫—Å–∏–º—É–º 50 –ú–ë.")
        except Exception:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
            pass
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        response = await client.get(download_url, headers=headers)
        response.raise_for_status()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        if len(response.content) > 50 * 1024 * 1024:
            raise ValueError(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({len(response.content) / 1024 / 1024:.1f} –ú–ë). –ú–∞–∫—Å–∏–º—É–º 50 –ú–ë.")
        
        return response.content

def is_valid_file_url(text: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –≤–∞–ª–∏–¥–Ω–æ–π —Å—Å—ã–ª–∫–æ–π –Ω–∞ Dropbox.
    """
    url_pattern = r'https?://[^\s]+'
    if not re.match(url_pattern, text):
        return False
    
    return 'dropbox.com' in text.lower()

# --- Google Cloud Storage —Ñ—É–Ω–∫—Ü–∏–∏ ---

def prepare_telegram_image(page, user_id: int) -> io.BytesIO:
    """
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram
    —Å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    """
    # Telegram Photo API –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:
    # - –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: –¥–æ 10MB
    # - –†–∞–∑–º–µ—Ä—ã: –æ—Ç 10x10 –¥–æ 10000x10000 –ø–∏–∫—Å–µ–ª–µ–π
    # - –ù–æ –µ—Å—Ç—å –Ω–µ—è–≤–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω –∏ –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –ª–∏–º–∏—Ç—ã –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã
    MAX_WIDTH = 4096   # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ª–∏–º–∏—Ç –≤–º–µ—Å—Ç–æ 10000
    MAX_HEIGHT = 4096  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ª–∏–º–∏—Ç –≤–º–µ—Å—Ç–æ 10000 
    MAX_FILE_SIZE_MB = 8  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ª–∏–º–∏—Ç –≤–º–µ—Å—Ç–æ 10MB
    
    # –°–æ–∑–¥–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —É–º–µ—Ä–µ–Ω–Ω—ã–º DPI
    pix = page.get_pixmap(dpi=150)
    png_bytes = pix.tobytes("png")
    image = Image.open(io.BytesIO(png_bytes))
    
    original_width, original_height = image.size
    logger.info(f"[USER_ID: {user_id}] - Original image: {original_width}x{original_height}")
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –µ—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω—ã –ª–∏–º–∏—Ç—ã
    if original_width > MAX_WIDTH or original_height > MAX_HEIGHT:
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
        scale_factor = min(MAX_WIDTH / original_width, MAX_HEIGHT / original_height)
        new_width = int(original_width * scale_factor)
        new_height = int(original_height * scale_factor)
        
        image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        logger.info(f"[USER_ID: {user_id}] - Resized to: {new_width}x{new_height} (scale: {scale_factor:.2f})")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
    if image.width < 10 or image.height < 10:
        scale_factor = max(15 / image.width, 15 / image.height)
        new_width = int(image.width * scale_factor)
        new_height = int(image.height * scale_factor)
        image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        logger.info(f"[USER_ID: {user_id}] - Upscaled to meet minimum: {new_width}x{new_height}")
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º PNG
    img_buffer = io.BytesIO()
    image.save(img_buffer, format='PNG', optimize=True)
    img_buffer.seek(0)
    file_size_mb = len(img_buffer.getvalue()) / 1024 / 1024
    
    # –ï—Å–ª–∏ PNG —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JPEG
    if file_size_mb > MAX_FILE_SIZE_MB:
        logger.warning(f"[USER_ID: {user_id}] - PNG too large ({file_size_mb:.1f}MB), converting to JPEG")
        img_buffer = io.BytesIO()
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        for quality in [85, 75, 65, 55]:
            img_buffer = io.BytesIO()
            image.save(img_buffer, format='JPEG', quality=quality, optimize=True)
            img_buffer.seek(0)
            file_size_mb = len(img_buffer.getvalue()) / 1024 / 1024
            
            if file_size_mb <= MAX_FILE_SIZE_MB:
                logger.info(f"[USER_ID: {user_id}] - JPEG quality {quality}: {file_size_mb:.1f}MB")
                break
        
        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä
        if file_size_mb > MAX_FILE_SIZE_MB:
            scale_factor = 0.8
            new_width = int(image.width * scale_factor)
            new_height = int(image.height * scale_factor)
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            img_buffer = io.BytesIO()
            image.save(img_buffer, format='JPEG', quality=75, optimize=True)
            img_buffer.seek(0)
            file_size_mb = len(img_buffer.getvalue()) / 1024 / 1024
            logger.info(f"[USER_ID: {user_id}] - Final resize: {new_width}x{new_height}, {file_size_mb:.1f}MB")
    
    final_size_mb = len(img_buffer.getvalue()) / 1024 / 1024
    logger.info(f"[USER_ID: {user_id}] - Final Telegram image: {image.width}x{image.height}, {final_size_mb:.1f}MB")
    
    return img_buffer

def clean_filename(filename: str) -> str:
    """–û—á–∏—â–∞–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ GCS"""
    if not filename:
        return "unknown"
    
    # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
    name = os.path.splitext(filename)[0]
    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
    name = name.replace(" ", "_")
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∞–ª—Ñ–∞–≤–∏—Ç, —Ü–∏—Ñ—Ä—ã –∏ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
    name = re.sub(r'[^a-zA-Z–∞-—è—ë–ê-–Ø–Å0-9_]', '', name)
    
    return name or "unknown"

def format_utc_timestamp() -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ UTC –¥–ª—è –∏–º–µ–Ω–∏ –ø–∞–ø–∫–∏"""
    now = datetime.now(timezone.utc)
    # –§–æ—Ä–º–∞—Ç: 2025-08-02T14-30-45Z (–¥–≤–æ–µ—Ç–æ—á–∏—è –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ –¥–µ—Ñ–∏—Å—ã)
    return now.strftime("%Y-%m-%dT%H-%M-%SZ")

async def save_to_yandex_initial(
    user_id: int,
    pdf_name: str,
    page_image_bytes: bytes,
    ocr_html: str,
    corrected_json: dict,
    find_prompt: str,
    extract_prompt: str
) -> Optional[str]:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞—á–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ Yandex Object Storage –ë–ï–ó —Å–æ–∑–¥–∞–Ω–∏—è parquet
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç base_path –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    """
    if not yandex_storage.client:
        logger.warning("Yandex Storage not configured, skipping initial save")
        return None
    
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å
        timestamp = format_utc_timestamp()
        clean_pdf_name = clean_filename(pdf_name)
        base_path = f"user_{user_id}/{clean_pdf_name}_{timestamp}"
        
        logger.info(f"[USER_ID: {user_id}] - Initial save to Yandex Storage: {base_path}")
        
        # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º input.webp (–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WebP lossless)
        try:
            webp_buffer = io.BytesIO()
            image = Image.open(io.BytesIO(page_image_bytes))
            image.save(webp_buffer, format='WEBP', lossless=True)
            webp_bytes = webp_buffer.getvalue()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º
            temp_webp = f"/tmp/temp_webp_{user_id}.webp"
            with open(temp_webp, 'wb') as f:
                f.write(webp_bytes)
            
            if not yandex_storage.upload_file(temp_webp, f"{base_path}/input.webp", 'image/webp'):
                raise Exception("Failed to upload WebP")
            
            os.remove(temp_webp)
            
        except Exception as img_error:
            # –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ PNG
            logger.warning(f"[USER_ID: {user_id}] - WebP conversion failed, saving as PNG: {img_error}")
            temp_png = f"/tmp/temp_png_{user_id}.png"
            with open(temp_png, 'wb') as f:
                f.write(page_image_bytes)
            
            if not yandex_storage.upload_file(temp_png, f"{base_path}/input.png", 'image/png'):
                raise Exception("Failed to upload PNG")
            
            os.remove(temp_png)
        
        # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º ocr_raw.html.gz
        if not yandex_storage.upload_gzipped_string(ocr_html, f"{base_path}/ocr_raw.html.gz", 'text/html'):
            raise Exception("Failed to upload OCR HTML")
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º corrected.json
        if not yandex_storage.upload_json(corrected_json, f"{base_path}/corrected.json"):
            raise Exception("Failed to upload corrected JSON")
        
        # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º find_prompt.txt
        if not yandex_storage.upload_string(find_prompt, f"{base_path}/find_prompt.txt", 'text/plain'):
            raise Exception("Failed to upload find prompt")
        
        # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º extract_prompt.txt
        if not yandex_storage.upload_string(extract_prompt, f"{base_path}/extract_prompt.txt", 'text/plain'):
            raise Exception("Failed to upload extract prompt")
        
        # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º meta.json
        meta_data = {
            "user_id": user_id,
            "pdf_name": pdf_name,
            "clean_pdf_name": clean_pdf_name,
            "timestamp": timestamp,
            "timestamp_iso": datetime.now(timezone.utc).isoformat(),
            "find_prompt_length": len(find_prompt),
            "extract_prompt_length": len(extract_prompt),
            "processing_id": str(uuid.uuid4()),
            "feedback_status": "pending"  # –û–∂–∏–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        }
        
        if not yandex_storage.upload_json(meta_data, f"{base_path}/meta.json"):
            raise Exception("Failed to upload meta JSON")
        
        logger.info(f"[USER_ID: {user_id}] - Initial save successful: {base_path}")
        return base_path
        
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error in save_to_yandex_initial: {e}", exc_info=True)
        return None

def schedule_feedback_timeout(user_id: int, base_path: str, timeout_seconds: int = 1800):
    """
    –ü–ª–∞–Ω–∏—Ä—É–µ—Ç –∑–∞–¥–∞—á—É –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É timeout –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ (30 –º–∏–Ω—É—Ç)
    """
    def timeout_handler():
        time.sleep(timeout_seconds)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞–¥–∞—á–∞ –Ω–µ –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞
        if user_id in pending_feedback_tasks and not pending_feedback_tasks[user_id].get("cancel", False):
            logger.info(f"[USER_ID: {user_id}] - Feedback timeout reached, finalizing with 'timeout'")
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—é –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(finalize_yandex_entry(base_path, "timeout"))
            loop.close()
            # –£–¥–∞–ª—è–µ–º –∑–∞–¥–∞—á—É –∏–∑ pending
            pending_feedback_tasks.pop(user_id, None)
    
    # –û—Ç–º–µ–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –∑–∞–¥–∞—á—É –µ—Å–ª–∏ –µ—Å—Ç—å
    if user_id in pending_feedback_tasks:
        pending_feedback_tasks[user_id]["cancel"] = True
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
    pending_feedback_tasks[user_id] = {
        "base_path": base_path,
        "cancel": False,
        "started_at": datetime.now(timezone.utc)
    }
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    thread = threading.Thread(target=timeout_handler, daemon=True)
    thread.start()
    
    logger.info(f"[USER_ID: {user_id}] - Scheduled feedback timeout in {timeout_seconds//60} minutes")

async def finalize_yandex_entry(base_path: str, feedback_status: str):
    """
    –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø–∏—Å—å –≤ Yandex Storage: –æ–±–Ω–æ–≤–ª—è–µ—Ç meta.json –∏ —Å–æ–∑–¥–∞–µ—Ç parquet
    feedback_status: 'good', 'bad', –∏–ª–∏ 'timeout'
    """
    if not yandex_storage.client:
        logger.warning("Yandex Storage not configured, skipping finalization")
        return
    
    try:
        logger.info(f"Finalizing Yandex entry: {base_path} with feedback: {feedback_status}")
        
        # 1. –ß–∏—Ç–∞–µ–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º meta.json —Å feedback_status
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        temp_meta = f"/tmp/temp_meta_{uuid.uuid4().hex}.json"
        
        if yandex_storage.download_file(f"{base_path}/meta.json", temp_meta):
            with open(temp_meta, 'r', encoding='utf-8') as f:
                meta_data = json.load(f)
            
            meta_data["feedback_status"] = feedback_status
            meta_data["feedback_received_at"] = datetime.now(timezone.utc).isoformat()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π meta.json
            if not yandex_storage.upload_json(meta_data, f"{base_path}/meta.json"):
                raise Exception("Failed to upload updated meta.json")
            
            os.remove(temp_meta)
        else:
            logger.error(f"Meta.json not found at {base_path}/meta.json")
            return
        
        # 2. –°–æ–∑–¥–∞–µ–º feedback.txt
        feedback_messages = {
            "good": f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–≤–æ–ª–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏\n–í—Ä–µ–º—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏: {datetime.now(timezone.utc).isoformat()}",
            "bad": f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ù–ï –¥–æ–≤–æ–ª–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏\n–í—Ä–µ–º—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏: {datetime.now(timezone.utc).isoformat()}\n–ö–æ–Ω—Ç–∞–∫—Ç –∞–¥–º–∏–Ω–∞: @aianback",
            "timeout": f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å (timeout)\n–í—Ä–µ–º—è –∏—Å—Ç–µ—á–µ–Ω–∏—è: {datetime.now(timezone.utc).isoformat()}"
        }
        
        feedback_content = feedback_messages.get(feedback_status, "Unknown feedback status")
        if not yandex_storage.upload_string(feedback_content, f"{base_path}/feedback.txt", 'text/plain'):
            raise Exception("Failed to upload feedback.txt")
        
        # 3. –°–æ–∑–¥–∞–µ–º parquet –∑–∞–ø–∏—Å—å
        await create_parquet_entry_yandex(base_path, meta_data, feedback_status)
        
        logger.info(f"Successfully finalized Yandex entry: {base_path}")
        
    except Exception as e:
        logger.error(f"Error finalizing Yandex entry {base_path}: {e}", exc_info=True)

async def create_parquet_entry_yandex(base_path: str, meta_data: dict, feedback_status: str):
    """
    –°–æ–∑–¥–∞–µ—Ç –∑–∞–ø–∏—Å—å –≤ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–º parquet —Ñ–∞–π–ª–µ –≤ Yandex Storage
    """
    try:
        if not yandex_storage.client:
            return
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
        parquet_path = f"dataset/{today}.parquet"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º corrected.json –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        temp_corrected = f"/tmp/temp_corrected_{uuid.uuid4().hex}.json"
        corrected_data = {}
        
        if yandex_storage.download_file(f"{base_path}/corrected.json", temp_corrected):
            with open(temp_corrected, 'r', encoding='utf-8') as f:
                corrected_data = json.load(f)
            os.remove(temp_corrected)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ—Ñ–∏–ª–µ–π
        profiles_count = 0
        total_mass = 0.0
        profile_types = set()
        
        if "–ø—Ä–æ—Ñ–∏–ª–∏" in corrected_data:
            for profile_name, profile_data in corrected_data["–ø—Ä–æ—Ñ–∏–ª–∏"].items():
                profiles_count += 1
                profile_types.add(profile_name)
                if isinstance(profile_data, dict) and "–º–∞—Ä–∫–∏_—Å—Ç–∞–ª–∏" in profile_data:
                    for steel_grade, steel_data in profile_data["–º–∞—Ä–∫–∏_—Å—Ç–∞–ª–∏"].items():
                        if isinstance(steel_data, dict) and "—Ä–∞–∑–º–µ—Ä—ã" in steel_data:
                            for size_name, size_data in steel_data["—Ä–∞–∑–º–µ—Ä—ã"].items():
                                if isinstance(size_data, dict) and "—ç–ª–µ–º–µ–Ω—Ç—ã" in size_data:
                                    for element in size_data["—ç–ª–µ–º–µ–Ω—Ç—ã"]:
                                        if isinstance(element, dict) and "–º–∞—Å—Å–∞" in element:
                                            try:
                                                total_mass += float(element["–º–∞—Å—Å–∞"])
                                            except (ValueError, TypeError):
                                                pass
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –¥–ª—è parquet
        record = {
            "timestamp": meta_data.get("timestamp_iso", datetime.now(timezone.utc).isoformat()),
            "user_id": meta_data.get("user_id", 0),
            "pdf_name": meta_data.get("pdf_name", "unknown"),
            "processing_id": meta_data.get("processing_id", str(uuid.uuid4())),
            "feedback_status": feedback_status,
            "profiles_found": profiles_count,
            "total_mass_tons": round(total_mass, 3),
            "unique_profile_types": len(profile_types),
            "find_prompt_length": meta_data.get("find_prompt_length", 0),
            "extract_prompt_length": meta_data.get("extract_prompt_length", 0),
            "yandex_path": base_path
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ parquet —Ñ–∞–π–ª –∑–∞ —Å–µ–≥–æ–¥–Ω—è
        temp_parquet = f"/tmp/temp_parquet_{uuid.uuid4().hex}.parquet"
        
        if yandex_storage.file_exists(parquet_path):
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
            if yandex_storage.download_file(parquet_path, temp_parquet):
                # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
                existing_df = pd.read_parquet(temp_parquet)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
                new_df = pd.DataFrame([record])
                combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                
                os.remove(temp_parquet)
            else:
                # –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ - —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame
                combined_df = pd.DataFrame([record])
        else:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame
            combined_df = pd.DataFrame([record])
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π parquet
        combined_df.to_parquet(temp_parquet, index=False)
        
        if yandex_storage.upload_file(temp_parquet, parquet_path, 'application/octet-stream'):
            logger.info(f"Updated parquet dataset: {parquet_path} (total records: {len(combined_df)})")
        else:
            logger.error(f"Failed to upload parquet dataset: {parquet_path}")
        
        os.remove(temp_parquet)
        
    except Exception as e:
        logger.error(f"Error creating parquet entry: {e}", exc_info=True)


# --- –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ --- 

async def process_specification(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat = update.effective_chat
    user_id = update.effective_user.id
    try:
        pdf_bytes = context.user_data["pdf_bytes"]
        page_number = context.user_data.get("manual_page_number") or context.user_data.get("found_page_number")

        # –≠—Ç–∞–ø 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ PNG –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å Azure
        logger.info(f"[USER_ID: {user_id}] - STEP 2: Extracting page {page_number} to PNG and sending to Azure...")
        
        step2_message = f"""‚öôÔ∏è –≠—Ç–∞–ø 2/4: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞

üì∑ –ò–∑–≤–ª–µ–∫–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_number} –≤ –≤—ã—Å–æ–∫–æ–º –∫–∞—á–µ—Å—Ç–≤–µ...
üîç –û—Ç–ø—Ä–∞–≤–ª—è—é –≤ Azure OCR –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...

*–û–ø—Ä–µ–¥–µ–ª—è—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü –∏ –∏–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç*"""
        
        await chat.send_message(step2_message)
        pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if page_number > len(pdf_document):
            pdf_document.close()
            await chat.send_message(f"–û—à–∏–±–∫–∞: —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –î–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ {len(pdf_document)} —Å—Ç—Ä–∞–Ω–∏—Ü.")
            return
        
        page_to_ocr = pdf_document.load_page(page_number - 1)
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å DPI 300, –Ω–æ —É–º–µ–Ω—å—à–∞–µ–º –µ—Å–ª–∏ —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
        dpi = 300
        max_file_size = 4 * 1024 * 1024  # 4MB –ª–∏–º–∏—Ç –¥–ª—è Azure
        
        while dpi >= 150:
            pix = page_to_ocr.get_pixmap(dpi=dpi)
            png_bytes = pix.tobytes("png")
            
            if len(png_bytes) <= max_file_size:
                logger.info(f"[USER_ID: {user_id}] - Using DPI {dpi}, image size: {len(png_bytes) / 1024 / 1024:.1f}MB")
                break
            else:
                logger.warning(f"[USER_ID: {user_id}] - DPI {dpi} too large ({len(png_bytes) / 1024 / 1024:.1f}MB), reducing...")
                dpi -= 50
        
        if len(png_bytes) > max_file_size:
            pdf_document.close()
            await chat.send_message("–û—à–∏–±–∫–∞: —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å –¥—Ä—É–≥–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º.")
            return
            
        pdf_document.close()

        async with DocumentIntelligenceClient(endpoint=AZURE_ENDPOINT, credential=AzureKeyCredential(AZURE_KEY)) as client:
            poller = await client.begin_analyze_document("prebuilt-layout", png_bytes, content_type="application/octet-stream")
            result = await poller.result()
        if not result.tables:
            await chat.send_message("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–∞–±–ª–∏—Ü—É –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ.")
            return

        # --- –û–±—ä–µ–¥–∏–Ω—è–µ–º –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –≤ –æ–¥–∏–Ω HTML –¥–ª—è Gemini ---
        all_tables_html_parts = [table_to_html(table) for table in result.tables]
        full_html_content = "\n<hr>\n".join(all_tables_html_parts) # –°–æ–µ–¥–∏–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—ã –ª–∏–Ω–∏–µ–π
        logger.info(f"[USER_ID: {user_id}] - Combined HTML from {len(result.tables)} tables generated for Gemini.")

        # --- –û–¢–õ–ê–î–ö–ê: –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç—Ç–æ—Ç –∂–µ HTML –≤ —Ñ–∞–π–ª ---
        debug_file_path = os.path.join(TEMP_DIR, f"azure_output_{user_id}.html")
        with open(debug_file_path, "w", encoding="utf-8") as f:
            f.write(full_html_content)
        logger.info(f"[USER_ID: {user_id}] - Azure OCR debug HTML saved to {debug_file_path}")
        # --- –ö–û–ù–ï–¶ –û–¢–õ–ê–î–ö–ò ---

        # –≠—Ç–∞–ø 3: –ï–¥–∏–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON
        logger.info(f"[USER_ID: {user_id}] - STEP 3: Correcting and extracting JSON with Gemini...")
        
        step3_message = """ü§ñ –≠—Ç–∞–ø 3/4: –ò–ò –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

‚ú® –ò—Å–ø—Ä–∞–≤–ª—è—é –æ—à–∏–±–∫–∏ OCR —Å –ø–æ–º–æ—â—å—é Gemini...
üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç JSON...
üîß –ü—Ä–∏–º–µ–Ω—è—é –ø—Ä–∞–≤–∏–ª–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –º–µ—Ç–∞–ª–ª–æ–ø—Ä–æ–∫–∞—Ç–∞...

*–≠—Ç–æ —Å–∞–º—ã–π —Å–ª–æ–∂–Ω—ã–π —ç—Ç–∞–ø, –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã*"""
        
        await chat.send_message(step3_message)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
        json_data = await run_gemini_with_fallback(full_html_content, user_id, chat)
        logger.info(f"[USER_ID: {user_id}] - JSON extracted successfully.")

        # --- –û–¢–õ–ê–î–ö–ê: –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é ---
        json_file_path = os.path.join(TEMP_DIR, f"structured_output_{user_id}.json")
        with open(json_file_path, "w", encoding="utf-8") as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        logger.info(f"[USER_ID: {user_id}] - JSON structured data saved to {json_file_path}")
        # --- –ö–û–ù–ï–¶ –û–¢–õ–ê–î–ö–ò JSON ---

        # –≠—Ç–∞–ø 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
        step4_message = """üìà –≠—Ç–∞–ø 4/4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤

üìä –°–æ–∑–¥–∞—é Excel —Ç–∞–±–ª–∏—Ü—É...
üìÑ –§–æ—Ä–º–∏—Ä—É—é —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç...
üíæ –°–æ—Ö—Ä–∞–Ω—è—é –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞—Ä—Ö–∏–≤–∞...

*–ü–æ—á—Ç–∏ –≥–æ—Ç–æ–≤–æ!*"""
        
        await chat.send_message(step4_message)
        
        df = flatten_json_to_dataframe(json_data)
        txt_buffer = io.BytesIO(df.to_string(index=False).encode('utf-8'))
        xlsx_buffer = io.BytesIO()
        df.to_excel(xlsx_buffer, index=False, engine='openpyxl')
        xlsx_buffer.seek(0)

        # –≠—Ç–∞–ø 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Google Cloud Storage –¥–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞
        pdf_file_name = context.user_data.get("pdf_file_name", "unknown")
        logger.info(f"[USER_ID: {user_id}] - STEP 5: Saving to GCS for fine-tuning...")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç—ã –∏–∑ —Ñ–∞–π–ª–æ–≤
        find_prompt = get_prompt("find_and_validate.txt")
        extract_prompt = get_prompt("extract_and_correct.txt")
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è (DPI 300)
        pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
        page_for_archive = pdf_document.load_page(page_number - 1)
        archive_pix = page_for_archive.get_pixmap(dpi=300)  # –í—Å–µ–≥–¥–∞ –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –∞—Ä—Ö–∏–≤–∞
        archive_png_bytes = archive_pix.tobytes("png")
        pdf_document.close()
        
        logger.info(f"[USER_ID: {user_id}] - Archive image: {len(archive_png_bytes) / 1024 / 1024:.1f}MB at 300 DPI")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ GCS –ë–ï–ó —Å–æ–∑–¥–∞–Ω–∏—è parquet (–æ–Ω –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –ø–æ—Å–ª–µ feedback)
        base_path = await save_to_yandex_initial(
            user_id=user_id,
            pdf_name=pdf_file_name,
            page_image_bytes=archive_png_bytes,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ä—Ö–∏–≤–Ω—É—é –≤–µ—Ä—Å–∏—é!
            ocr_html=full_html_content,
            corrected_json=json_data,
            find_prompt=find_prompt,
            extract_prompt=extract_prompt
        )
        
        # –ü–ª–∞–Ω–∏—Ä—É–µ–º timeout –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        if base_path:
            schedule_feedback_timeout(user_id, base_path, FEEDBACK_TIMEOUT_SECONDS)

        success_message = """üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!

üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:
‚Ä¢ ‚úÖ –î–∞–Ω–Ω—ã–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω—ã
‚Ä¢ ‚úÖ –û—à–∏–±–∫–∏ OCR –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
‚Ä¢ ‚úÖ –°–æ–∑–¥–∞–Ω—ã –æ—Ç—á–µ—Ç—ã –≤ –¥–≤—É—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö

üìÅ –ü–æ–ª—É—á–∏—Ç–µ –≤–∞—à–∏ —Ñ–∞–π–ª—ã:"""

        await chat.send_message(success_message)
        await chat.send_document(
            document=InputFile(xlsx_buffer, filename="specification.xlsx"),
            caption="üìà Excel —Ñ–∞–π–ª - –≥–æ—Ç–æ–≤ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö"
        )
        await chat.send_document(
            document=InputFile(txt_buffer, filename="specification.txt"), 
            caption="üìÑ –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª - –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è"
        )
        
        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ OCR
        if "–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ OCR" in str(json_data):
            try:
                ocr_buffer = io.BytesIO(full_html_content.encode('utf-8'))
                await chat.send_document(
                    document=InputFile(ocr_buffer, filename="ocr_raw_data.html"),
                    caption="üîß **–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ OCR** - –¥–ª—è —Ä—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–æ—Ç–∫—Ä–æ–π—Ç–µ –≤ –±—Ä–∞—É–∑–µ—Ä–µ)"
                )
            except Exception:
                pass
        logger.info(f"[USER_ID: {user_id}] - FINAL: Reports sent.")
        
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        feedback_keyboard = [
            [InlineKeyboardButton("üëç –î–∞, –≤—Å—ë –æ—Ç–ª–∏—á–Ω–æ!", callback_data="feedback_yes")],
            [InlineKeyboardButton("üëé –ï—Å—Ç—å –æ—à–∏–±–∫–∏", callback_data="feedback_no")]
        ]
        feedback_message = """üìù –í—ã –¥–æ–≤–æ–ª—å–Ω—ã –∫–∞—á–µ—Å—Ç–≤–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏?

–í–∞—à –æ—Ç–∑—ã–≤ –ø–æ–º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤!

‚Ä¢ üëç –î–∞ - –µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞—Å —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç
‚Ä¢ üëé –ï—Å—Ç—å –æ—à–∏–±–∫–∏ - –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏ –∏–ª–∏ –æ—à–∏–±–∫–∏

–ü—Ä–∏ –≤—ã–±–æ—Ä–µ "–ï—Å—Ç—å –æ—à–∏–±–∫–∏" –≤—ã —Å–º–æ–∂–µ—Ç–µ —Å–≤—è–∑–∞—Ç—å—Å—è —Å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º."""
        
        await chat.send_message(
            feedback_message,
            reply_markup=InlineKeyboardMarkup(feedback_keyboard)
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ (–≤–∫–ª—é—á–∞—è base_path)
        context.user_data["processed_files"] = {
            "user_id": user_id,
            "pdf_name": pdf_file_name,
            "page_image_bytes": archive_png_bytes,
            "ocr_html": full_html_content,
            "corrected_json": json_data,
            "find_prompt": find_prompt,
            "extract_prompt": extract_prompt,
            "base_path": base_path  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
        }
        
        return AWAITING_FEEDBACK

    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error in process_specification: {e}", exc_info=True)
        await chat.send_message("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ.")
        return ConversationHandler.END

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_message = """ü§ñ –ü—Ä–∏–≤–µ—Ç! –Ø –≤–∞—à –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π –º–µ—Ç–∞–ª–ª–æ–ø—Ä–æ–∫–∞—Ç–∞!

‚ú® –ß—Ç–æ —è —É–º–µ—é:
‚Ä¢ üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é PDF –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –ø–æ–º–æ—â—å—é –ò–ò
‚Ä¢ üìä –ò–∑–≤–ª–µ–∫–∞—é —Ç–∞–±–ª–∏—Ü—ã —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π
‚Ä¢ ‚úÖ –ò—Å–ø—Ä–∞–≤–ª—è—é –æ—à–∏–±–∫–∏ OCR –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏  
‚Ä¢ üìà –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç—á–µ—Ç—ã –≤ Excel –∏ TXT

üìé –ó–∞–≥—Ä—É–∑–∏—Ç–µ PDF-—Ñ–∞–π–ª (–¥–æ 20 –ú–ë) –∏–ª–∏ 
üîó –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É —Å Dropbox

üí° –°–æ–≤–µ—Ç: –î–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Dropbox: https://dropbox.com

üöÄ –ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ! –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –¥–æ–∫—É–º–µ–Ω—Ç!"""
    
    await update.message.reply_text(welcome_message)
    return SELECTING_ACTION

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    
    if not update.message.document:
        return

    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ –ü–ï–†–ï–î —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ–º ---
    if update.message.document.file_size > 20 * 1024 * 1024: # 20 MB limit
        file_size_mb = update.message.document.file_size / 1024 / 1024
        logger.warning(f"[USER_ID: {user_id}] - PDF rejected: file too large ({file_size_mb:.2f} MB).")
        
        # –ö—Ä–∞—Å–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        message = f"""üìÅ –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({file_size_mb:.1f} –ú–ë)

üö´ Telegram –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Ñ–∞–π–ª—ã –¥–æ 20 –ú–ë
‚úÖ –ù–æ –º—ã –º–æ–∂–µ–º –ø–æ–º–æ—á—å!

üîó **–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –Ω–∞ Dropbox:**
üëâ https://dropbox.com

üì§ **–ó–∞—Ç–µ–º –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Å—Å—ã–ª–∫—É** –∏ —è –æ–±—Ä–∞–±–æ—Ç–∞—é –≤–∞—à –¥–æ–∫—É–º–µ–Ω—Ç

üí° **–°–æ–≤–µ—Ç:** –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å—Å—ã–ª–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∞ –¥–ª—è –æ–±—â–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞

üëá **–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É —Å Dropbox –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å:**"""

        await update.message.reply_text(message)
        return AWAITING_URL

    file_id = update.message.document.file_id
    file_name = update.message.document.file_name
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ GCS  
    context.user_data["pdf_file_name"] = file_name
    
    loading_message = f"""üì• –§–∞–π–ª –ø—Ä–∏–Ω—è—Ç! 

üìÑ –ò–º—è: `{file_name}`
üìä –†–∞–∑–º–µ—Ä: {update.message.document.file_size / 1024 / 1024:.1f} –ú–ë

‚è≥ –ó–∞–≥—Ä—É–∂–∞—é –¥–æ–∫—É–º–µ–Ω—Ç... 
*–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥*"""
    
    await update.message.reply_text(loading_message)

    try:
        file_info = await context.bot.get_file(file_id)
        
        file_url = file_info.file_path

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º httpx –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –ø–æ—Ç–æ–∫–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        async with httpx.AsyncClient() as client:
            async with client.stream("GET", file_url) as response:
                response.raise_for_status() # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫–∏ HTTP
                
                pdf_bytes_io = io.BytesIO()
                async for chunk in response.aiter_bytes():
                    pdf_bytes_io.write(chunk)
                pdf_bytes_io.seek(0)
                pdf_bytes = pdf_bytes_io.read()

        context.user_data["pdf_bytes"] = pdf_bytes
        logger.info(f"[USER_ID: {user_id}] - File '{file_name}' downloaded successfully.")

    except telegram.error.BadRequest as e:
        logger.error(f"[USER_ID: {user_id}] - Error getting file info: {e}", exc_info=True)
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ: {e}")
        return ConversationHandler.END
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error downloading file: {e}", exc_info=True)
        await update.message.reply_text(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞.")
        return ConversationHandler.END

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
    try:
        pdf_document_for_check = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
        num_pages = len(pdf_document_for_check)
        pdf_document_for_check.close()
        if num_pages > 100:
            logger.warning(f"[USER_ID: {user_id}] - PDF rejected: too many pages ({num_pages}).")
            await update.message.reply_text(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({num_pages} —Å—Ç—Ä–∞–Ω–∏—Ü). –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –Ω–µ –±–æ–ª–µ–µ 100 —Å—Ç—Ä–∞–Ω–∏—Ü.")
            return ConversationHandler.END
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Failed to check PDF page count: {e}")
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ PDF. –§–∞–π–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω.")
        return ConversationHandler.END

    analysis_message = """‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!

üîç –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞...
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—è—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
‚Ä¢ –ò—â—É —Ç–∞–±–ª–∏—Ü—ã —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π  
‚Ä¢ –û–ø—Ä–µ–¥–µ–ª—è—é –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏

ü§ñ –ò–ò –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞... 
*–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ –¥–æ 2 –º–∏–Ω—É—Ç (–±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –¥–æ–ª—å—à–µ)*"""
    
    await update.message.reply_text(analysis_message)

    temp_pdf_path = None
    try:
        os.makedirs(TEMP_DIR, exist_ok=True)
        temp_pdf_path = os.path.join(TEMP_DIR, f"{user_id}_check.pdf")
        with open(temp_pdf_path, "wb") as f:
            f.write(pdf_bytes)

        logger.info(f"[USER_ID: {user_id}] - STEP 1: Performing validation and page search with Gemini.")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞
        status_task = asyncio.create_task(send_periodic_status_updates(update, user_id, "–∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞"))
        
        try:
            prompt = get_prompt("find_and_validate.txt")
            model = create_gemini_model()

            if USE_VERTEX_AI:
                try:
                    from vertexai.generative_models import Part as VPart
                    with open(temp_pdf_path, 'rb') as f:
                        pdf_data = f.read()
                    file_part = VPart.from_data(pdf_data, mime_type="application/pdf")
                    response = await run_gemini_with_retry(
                        model,
                        prompt,
                        file_part,
                        user_id,
                        generation_config=GenerationConfig(response_mime_type="application/json")
                    )
                except Exception as e:
                    logger.error(f"[USER_ID: {user_id}] - Vertex path failed: {e}", exc_info=True)
                    await update.message.reply_text("Vertex AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.")
                    return ConversationHandler.END
            else:
                gemini_file = genai.upload_file(path=temp_pdf_path)
                # –ñ–¥–µ–º –ø–æ–∫–∞ —Ñ–∞–π–ª –ø–µ—Ä–µ–π–¥–µ—Ç –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ ACTIVE, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å 500 Internal errors
                try:
                    gemini_file = await wait_for_gemini_file_active(gemini_file, user_id)
                except Exception as wait_err:
                    logger.error(f"[USER_ID: {user_id}] - Gemini file not ready: {wait_err}")
                    await update.message.reply_text("–°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É.")
                    return ConversationHandler.END
                
                response = await run_gemini_with_retry(
                    model,
                    prompt,
                    gemini_file,
                    user_id,
                    generation_config=GenerationConfig(response_mime_type="application/json")
                )
                genai.delete_file(gemini_file.name)

            try:
                result = parse_gemini_json(response, user_id, debug_tag="find_validate")
            except (json.JSONDecodeError, AttributeError, ValueError) as e:
                logger.error(f"[USER_ID: {user_id}] - Failed to decode Gemini response: {e}", exc_info=True)
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–∏—Å–∞ –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")
                return ConversationHandler.END
        finally:
            # –û—Ç–º–µ–Ω—è–µ–º –∑–∞–¥–∞—á—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞
            status_task.cancel()
            try:
                await status_task
            except asyncio.CancelledError:
                pass

        page_number = result.get("page", 0)
        if page_number == 0:
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—É. –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –≤—Ä—É—á–Ω—É—é.")
            return AWAITING_MANUAL_PAGE

        context.user_data["found_page_number"] = page_number
        pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
        page = pdf_document.load_page(page_number - 1)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è Telegram
        img_buffer = prepare_telegram_image(page, user_id)
        pdf_document.close()

        keyboard = [[InlineKeyboardButton("‚úÖ –î–∞", callback_data="yes"), InlineKeyboardButton("‚ùå –ù–µ—Ç", callback_data="no")]]
        
        try:
            await update.message.reply_photo(
                photo=img_buffer,
                caption=f"–≠—Ç–æ –≤–µ—Ä–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number})?",
                reply_markup=InlineKeyboardMarkup(keyboard),
            )
        except telegram.error.BadRequest as e:
            if "Photo_invalid_dimensions" in str(e):
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                logger.warning(f"[USER_ID: {user_id}] - Failed to send photo, sending text message instead: {e}")
                await update.message.reply_text(
                    f"–ù–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number}. –≠—Ç–æ –≤–µ—Ä–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞?",
                    reply_markup=InlineKeyboardMarkup(keyboard)
                )
            else:
                raise e
                
        return AWAITING_CONFIRMATION

    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error in handle_document: {e}", exc_info=True)
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.")
        return ConversationHandler.END
    finally:
        if temp_pdf_path and os.path.exists(temp_pdf_path):
            os.remove(temp_pdf_path)

async def handle_confirmation_choice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    if query.data == "yes":
        # –ü—Ä–æ–±—É–µ–º –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å caption, –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        processing_message = """üéØ –û—Ç–ª–∏—á–Ω–æ! –°—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞!

üöÄ –ù–∞—á–∏–Ω–∞—é –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É:
‚Ä¢ üì∑ –ò–∑–≤–ª–µ–∫–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –≤—ã—Å–æ–∫–æ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏
‚Ä¢ üîç –†–∞—Å–ø–æ–∑–Ω–∞—é —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ Azure OCR
‚Ä¢ ü§ñ –ò—Å–ø—Ä–∞–≤–ª—è—é –æ—à–∏–±–∫–∏ —Å –ø–æ–º–æ—â—å—é –ò–ò
‚Ä¢ üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü—ã
‚Ä¢ üìà –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç—á–µ—Ç—ã Excel –∏ TXT

‚è∞ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 1-3 –º–∏–Ω—É—Ç—ã
*–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–∂–∏–¥–∞–π—Ç–µ...*"""

        try:
            await query.edit_message_caption(caption=processing_message)
        except telegram.error.BadRequest as e:
            if "There is no caption in the message to edit" in str(e):
                logger.info(f"No caption to edit, using edit_message_text instead: {e}")
                await query.edit_message_text(text=processing_message)
            else:
                raise e
        
        return await process_specification(update, context)
    else:
        # –ü—Ä–æ–±—É–µ–º –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å caption, –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        try:
            await query.edit_message_caption(caption="–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã:")
        except telegram.error.BadRequest as e:
            if "There is no caption in the message to edit" in str(e):
                logger.info(f"No caption to edit, using edit_message_text instead: {e}")
                await query.edit_message_text(text="–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã:")
            else:
                raise e
        
        return AWAITING_MANUAL_PAGE

async def handle_manual_page_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        page_number = int(update.message.text)
        context.user_data["manual_page_number"] = page_number
        await update.message.reply_text(f"–ü—Ä–∏–Ω—è—Ç–æ. –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}...")
        return await process_specification(update, context)
    except (ValueError):
        await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã.")
        return AWAITING_MANUAL_PAGE

async def handle_file_url(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–∞–π–ª —Å —Ñ–∞–π–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫–∞.
    """
    user_id = update.effective_user.id
    url = update.message.text.strip()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ URL –¥–ª—è Dropbox
    file_name_from_url = "unknown"
    try:
        # –î–ª—è Dropbox —Å—Å—ã–ª–æ–∫ –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ –ø—É—Ç–∏
        import urllib.parse
        parsed_url = urllib.parse.urlparse(url)
        path_parts = parsed_url.path.split('/')
        for part in path_parts:
            if part.endswith('.pdf'):
                file_name_from_url = part
                break
    except:
        file_name_from_url = "dropbox_file.pdf"
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ GCS
    context.user_data["pdf_file_name"] = file_name_from_url
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Å—Å—ã–ª–∫–∏
    if not is_valid_file_url(url):
        supported_services = """‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ Dropbox

üîó –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –Ω–∞ Dropbox:
üëâ https://dropbox.com

üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å—Å—ã–ª–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∞ –¥–ª—è –æ–±—â–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞"""
        await update.message.reply_text(supported_services)
        return AWAITING_URL
    
    await update.message.reply_text("üîÑ –°–∫–∞—á–∏–≤–∞—é —Ñ–∞–π–ª –ø–æ —Å—Å—ã–ª–∫–µ...")
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        pdf_bytes = await download_file_from_url(url, user_id)
        logger.info(f"[USER_ID: {user_id}] - File downloaded from URL: {len(pdf_bytes)} bytes")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ PDF
        try:
            pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
            num_pages = len(pdf_document)
            pdf_document.close()
        except Exception:
            await update.message.reply_text("‚ùå –§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º PDF-–¥–æ–∫—É–º–µ–Ω—Ç–æ–º.")
            return AWAITING_URL
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
        if num_pages > 100:
            await update.message.reply_text(f"‚ùå –î–æ–∫—É–º–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({num_pages} —Å—Ç—Ä–∞–Ω–∏—Ü). –ú–∞–∫—Å–∏–º—É–º 100 —Å—Ç—Ä–∞–Ω–∏—Ü.")
            return AWAITING_URL
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
        context.user_data["pdf_bytes"] = pdf_bytes
        await update.message.reply_text(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω! –î–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç {num_pages} —Å—Ç—Ä–∞–Ω–∏—Ü. –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑...")
        
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∫–∞–∫ –æ–±—ã—á–Ω–æ
        temp_pdf_path = None
        try:
            os.makedirs(TEMP_DIR, exist_ok=True)
            temp_pdf_path = os.path.join(TEMP_DIR, f"{user_id}_check.pdf")
            with open(temp_pdf_path, "wb") as f:
                f.write(pdf_bytes)

            logger.info(f"[USER_ID: {user_id}] - STEP 1: Performing validation and page search with Gemini.")
            gemini_file = genai.upload_file(path=temp_pdf_path)
            # –ñ–¥–µ–º –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º –º–æ–¥–µ–ª–∏
            try:
                gemini_file = await wait_for_gemini_file_active(gemini_file, user_id)
            except Exception as wait_err:
                logger.error(f"[USER_ID: {user_id}] - Gemini file not ready: {wait_err}")
                await update.message.reply_text("–°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É.")
                return ConversationHandler.END
            prompt = get_prompt("find_and_validate.txt")
            model = create_gemini_model()
            
            response = await run_gemini_with_retry(
                model,
                prompt,
                gemini_file,
                user_id,
                generation_config=GenerationConfig(response_mime_type="application/json")
            )
            genai.delete_file(gemini_file.name)

            try:
                cleaned_text = response.text.replace("```json", "").replace("```", "").strip()
                result = json.loads(cleaned_text)
            except (json.JSONDecodeError, AttributeError, ValueError) as e:
                logger.error(f"[USER_ID: {user_id}] - Failed to decode Gemini response: {e}", exc_info=True)
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–∏—Å–∞ –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")
                return ConversationHandler.END

            page_number = result.get("page", 0)
            if page_number == 0:
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—É. –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –≤—Ä—É—á–Ω—É—é.")
                return AWAITING_MANUAL_PAGE

            context.user_data["found_page_number"] = page_number
            pdf_document = fitz.open(stream=io.BytesIO(pdf_bytes), filetype="pdf")
            page = pdf_document.load_page(page_number - 1)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è Telegram
            img_buffer = prepare_telegram_image(page, user_id)
            pdf_document.close()

            keyboard = [[InlineKeyboardButton("‚úÖ –î–∞", callback_data="yes"), InlineKeyboardButton("‚ùå –ù–µ—Ç", callback_data="no")]]
            
            try:
                await update.message.reply_photo(
                    photo=img_buffer,
                    caption=f"–≠—Ç–æ –≤–µ—Ä–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number})?",
                    reply_markup=InlineKeyboardMarkup(keyboard),
                )
            except telegram.error.BadRequest as e:
                if "Photo_invalid_dimensions" in str(e):
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                    logger.warning(f"[USER_ID: {user_id}] - Failed to send photo, sending text message instead: {e}")
                    await update.message.reply_text(
                        f"–ù–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number}. –≠—Ç–æ –≤–µ—Ä–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞?",
                        reply_markup=InlineKeyboardMarkup(keyboard)
                    )
                else:
                    raise e
                    
            return AWAITING_CONFIRMATION

        except Exception as e:
            logger.error(f"[USER_ID: {user_id}] - Error in handle_file_url: {e}", exc_info=True)
            await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.")
            return ConversationHandler.END
        finally:
            if temp_pdf_path and os.path.exists(temp_pdf_path):
                os.remove(temp_pdf_path)
        
    except ValueError as e:
        # –û—à–∏–±–∫–∏ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        await update.message.reply_text(f"‚ùå {str(e)}")
        return AWAITING_URL
    except Exception as e:
        logger.error(f"[USER_ID: {user_id}] - Error downloading file from URL: {e}", exc_info=True)
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Å—ã–ª–∫—É –∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.")
        return AWAITING_URL

async def handle_feedback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    query = update.callback_query
    await query.answer()
    
    user_id = update.effective_user.id
    processed_files = context.user_data.get("processed_files", {})
    base_path = processed_files.get("base_path")
    
    if not base_path:
        await query.edit_message_text("‚ùå –û—à–∏–±–∫–∞: –¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        context.user_data.clear()
        return ConversationHandler.END
    
    # –û—Ç–º–µ–Ω—è–µ–º timeout –∑–∞–¥–∞—á—É
    if user_id in pending_feedback_tasks:
        pending_feedback_tasks[user_id]["cancel"] = True
        pending_feedback_tasks.pop(user_id, None)
        logger.info(f"[USER_ID: {user_id}] - Feedback timeout cancelled (user responded)")
    
    if query.data == "feedback_yes":
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–≤–æ–ª–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        await query.edit_message_text("‚úÖ –°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É! –í–∞—à –æ—Ç–∑—ã–≤ –ø–æ–º–æ–∂–µ—Ç –Ω–∞–º —É–ª—É—á—à–∞—Ç—å —Å–µ—Ä–≤–∏—Å.")
        
        # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º GCS –∑–∞–ø–∏—Å—å —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é
        await finalize_yandex_entry(base_path, "good")
        
        context.user_data.clear()
        return ConversationHandler.END
        
    elif query.data == "feedback_no":
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ–¥–æ–≤–æ–ª–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º - –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –¥–∏–∞–ª–æ–≥—É —Å –∞–¥–º–∏–Ω–æ–º
        contact_message = """‚ùå –ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ

üîß –ù–∞–ø–∏—à–∏—Ç–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å:
üë§ @aianback

üìù –û–ø–∏—à–∏—Ç–µ –ø—Ä–æ–±–ª–µ–º—É:
‚Ä¢ –ö–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ –æ—à–∏–±–∫–∏ –≤—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏  
‚Ä¢ –ù–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
‚Ä¢ –ß—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ

‚ö° –í–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏!

–°–ø–∞—Å–∏–±–æ –∑–∞ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å! üôè

üí¨ –ù–∞–∂–º–∏—Ç–µ –Ω–∞ @aianback —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å —á–∞—Ç"""
        
        # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ –¥–∏–∞–ª–æ–≥—É —Å –∞–¥–º–∏–Ω–æ–º
        admin_keyboard = [[InlineKeyboardButton("üí¨ –ù–∞–ø–∏—Å–∞—Ç—å –∞–¥–º–∏–Ω—É", url="https://t.me/aianback")]]
        
        await query.edit_message_text(
            contact_message,
            reply_markup=InlineKeyboardMarkup(admin_keyboard)
        )
        
        # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º GCS –∑–∞–ø–∏—Å—å —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é
        await finalize_yandex_entry(base_path, "bad")
        
        context.user_data.clear()
        return ConversationHandler.END

async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–î–µ–π—Å—Ç–≤–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")
    context.user_data.clear()
    return ConversationHandler.END

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—à–∏–±–∫–∏ –±–æ—Ç–∞"""
    logger.error(f"Exception while handling an update: {context.error}", exc_info=context.error)
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å update, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
    if isinstance(update, Update) and update.effective_chat:
        error_message = """üòî –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞!

üîß –ß—Ç–æ –¥–µ–ª–∞—Ç—å:
‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥
‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ (—Ç–æ–ª—å–∫–æ PDF)
‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–æ 20 –ú–ë

üí¨ –ù—É–∂–Ω–∞ –ø–æ–º–æ—â—å? –ù–∞–ø–∏—à–∏—Ç–µ /start –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞"""
        
        try:
            await context.bot.send_message(
                chat_id=update.effective_chat.id,
                text=error_message
            )
        except Exception:
            pass

def main():
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
    missing = []
    if not TELEGRAM_BOT_TOKEN:
        missing.append("TELEGRAM_BOT_TOKEN")
    if not AZURE_ENDPOINT:
        missing.append("AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT")
    if not AZURE_KEY:
        missing.append("AZURE_DOCUMENT_INTELLIGENCE_KEY")

    if USE_VERTEX_AI:
        # –î–ª—è Vertex: –Ω—É–∂–µ–Ω –ø—Ä–æ–µ–∫—Ç (–∏ –æ–±—ã—á–Ω–æ ADC –∫—Ä–µ–¥—ã —á–µ—Ä–µ–∑ GOOGLE_APPLICATION_CREDENTIALS –∏–ª–∏ gcloud ADC)
        if not VERTEX_PROJECT_ID:
            missing.append("VERTEX_PROJECT_ID")
    else:
        if not GEMINI_API_KEY:
            missing.append("GEMINI_API_KEY")

    if missing:
        logger.critical(f"FATAL: Missing required environment variables: {', '.join(missing)}")
        return
    
    if not GCS_BUCKET:
        logger.warning("GCS_BUCKET not configured - archiving will be disabled")

    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ webhook'–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
    try:
        import requests
        response = requests.post(f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/deleteWebhook")
        logger.info("Webhook deleted to prevent conflicts")
    except Exception as e:
        logger.warning(f"Could not delete webhook: {e}")

    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
    app.add_error_handler(error_handler)
    
    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("start", start)],
        states={
            SELECTING_ACTION: [
                MessageHandler(filters.Document.PDF, handle_document),
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_file_url)
            ],
            AWAITING_CONFIRMATION: [CallbackQueryHandler(handle_confirmation_choice)],
            AWAITING_MANUAL_PAGE: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_manual_page_input)],
            AWAITING_URL: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_file_url)],
            AWAITING_FEEDBACK: [CallbackQueryHandler(handle_feedback)],
        },
        fallbacks=[CommandHandler("cancel", cancel)],
        per_message=False,  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã –∫–æ–º–∞–Ω–¥
    )
    app.add_handler(conv_handler)
    
    logger.info("ü§ñ === BOT INITIALIZED SUCCESSFULLY ===")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã (webhook –∏–ª–∏ polling)
    webhook_url = os.getenv("WEBHOOK_URL")
    port = int(os.getenv("PORT", "8080"))
    
    if webhook_url:
        logger.info("üåê Starting in WEBHOOK mode...")
        logger.info(f"üîó Webhook URL: {webhook_url}")
        logger.info(f"üö™ Port: {port}")
        
        try:
            app.run_webhook(
                listen="0.0.0.0",
                port=port,
                webhook_url=webhook_url,
                drop_pending_updates=True,
                allowed_updates=Update.ALL_TYPES
            )
        except Exception as e:
            logger.critical(f"Failed to start webhook: {e}")
            raise
    else:
        logger.info("üìû Starting in POLLING mode...")
        
        try:
            app.run_polling(drop_pending_updates=True, allowed_updates=Update.ALL_TYPES)
        except Exception as e:
            logger.critical(f"Failed to start polling: {e}")
            raise

if __name__ == "__main__":
    main()
